# experiment_name: base_experiment # This can be overridden by CLI or defaults if not set
# log_dir: results/logs/${experiment_name} # Replaced by trainer.default_root_dir
seed_everything: 42
model:
  class_path: foundation_model.models.FlexibleMultiTaskModel
  init_args:
    enable_learnable_loss_balancer: true
    strict_loading: true
    shared_block_dims: [290, 128]
    task_configs:
      # Regression tasks
      - name: density
        type: REGRESSION
        data_column: Density (normalized)
        dims: [128, 64, 1]
        norm: true
        residual: false
        weight: 1.0
        enabled: true
        optimizer:
          optimizer_type: AdamW
          lr: 5.0e-3
          weight_decay: 0.01
          eps: 1.0e-06
          betas: [0.9, 0.999]
          scheduler_type: ReduceLROnPlateau
          mode: min
          factor: 0.5
          patience: 10
          min_lr: 1.0e-05

      - name: band_gap
        type: REGRESSION
        data_column: Band gap (normalized)
        dims: [128, 64, 1]
        norm: true
        residual: false
        weight: 1.0
        enabled: true
        optimizer:
          optimizer_type: AdamW
          lr: 5.0e-3
          weight_decay: 0.01
          eps: 1.0e-06
          betas: [0.9, 0.999]
          scheduler_type: ReduceLROnPlateau
          mode: min
          factor: 0.5
          patience: 10
          min_lr: 1.0e-05

      - name: efermi
        type: REGRESSION
        data_column: Efermi (normalized)
        dims: [128, 64, 1]
        norm: true
        residual: false
        weight: 1.0
        enabled: true
        optimizer:
          optimizer_type: AdamW
          lr: 5.0e-3
          weight_decay: 0.01
          eps: 1.0e-06
          betas: [0.9, 0.999]
          scheduler_type: ReduceLROnPlateau
          mode: min
          factor: 0.5
          patience: 10
          min_lr: 1.0e-05

      - name: final_energy
        type: REGRESSION
        data_column: Final energy per atom (normalized)
        dims: [128, 64, 1]
        norm: true
        residual: false
        weight: 1.0
        enabled: true
        optimizer:
          optimizer_type: AdamW
          lr: 5.0e-3
          weight_decay: 0.01
          eps: 1.0e-06
          betas: [0.9, 0.999]
          scheduler_type: ReduceLROnPlateau
          mode: min
          factor: 0.5
          patience: 10
          min_lr: 1.0e-05

      - name: total_magnetization
        type: REGRESSION
        data_column: Total magnetization (normalized)
        dims: [128, 64, 1]
        norm: true
        residual: false
        weight: 1.0
        enabled: true
        optimizer:
          optimizer_type: AdamW
          lr: 5.0e-3
          weight_decay: 0.01
          eps: 1.0e-06
          betas: [0.9, 0.999]
          scheduler_type: ReduceLROnPlateau
          mode: min
          factor: 0.5
          patience: 10
          min_lr: 1.0e-05

      - name: dielectric_total
        type: REGRESSION
        data_column: Dielectric total (normalized)
        dims: [128, 64, 1]
        norm: true
        residual: false
        weight: 1.0
        enabled: true
        optimizer:
          optimizer_type: AdamW
          lr: 5.0e-3
          weight_decay: 0.01
          eps: 1.0e-06
          betas: [0.9, 0.999]
          scheduler_type: ReduceLROnPlateau
          mode: min
          factor: 0.5
          patience: 10
          min_lr: 1.0e-05

      - name: dielectric_ionic
        type: REGRESSION
        data_column: Dielectric ionic (normalized)
        dims: [128, 64, 1]
        norm: true
        residual: false
        weight: 1.0
        enabled: true
        optimizer:
          optimizer_type: AdamW
          lr: 5.0e-3
          weight_decay: 0.01
          eps: 1.0e-06
          betas: [0.9, 0.999]
          scheduler_type: ReduceLROnPlateau
          mode: min
          factor: 0.5
          patience: 10
          min_lr: 1.0e-05

      - name: dielectric_electronic
        type: REGRESSION
        data_column: Dielectric electronic (normalized)
        dims: [128, 64, 1]
        norm: true
        residual: false
        weight: 1.0
        enabled: true
        optimizer:
          optimizer_type: AdamW
          lr: 5.0e-3
          weight_decay: 0.01
          eps: 1.0e-06
          betas: [0.9, 0.999]
          scheduler_type: ReduceLROnPlateau
          mode: min
          factor: 0.5
          patience: 10
          min_lr: 1.0e-05

      - name: formation_energy # Note: Duplicate task name, this might be an issue or intended for some reason.
        type: REGRESSION
        data_column: Formation energy per atom (normalized) # Assuming same column for this duplicate
        dims: [128, 64, 1]
        norm: true
        residual: false
        weight: 1.0
        enabled: true
        optimizer:
          optimizer_type: AdamW
          lr: 5.0e-3
          weight_decay: 0.01
          eps: 1.0e-06
          betas: [0.9, 0.999]
          scheduler_type: ReduceLROnPlateau
          mode: min
          factor: 0.5
          patience: 10
          min_lr: 1.0e-05

      - name: volume # Note: Duplicate task name, this might be an issue or intended for some reason.
        type: REGRESSION
        data_column: Volume (normalized) # Assuming same column for this duplicate
        dims: [128, 64, 1]
        norm: true
        residual: false
        weight: 1.0
        enabled: true
        optimizer:
          optimizer_type: AdamW
          lr: 5.0e-3
          weight_decay: 0.01
          eps: 1.0e-06
          betas: [0.9, 0.999]
          scheduler_type: ReduceLROnPlateau
          mode: min
          factor: 0.5
          patience: 10
          min_lr: 1.0e-05

      # Classification tasks
      - name: material_type # Note: Duplicate task name, this might be an issue or intended for some reason.
        type: CLASSIFICATION
        data_column: Material type (label) # Assuming same column for this duplicate
        dims: [128, 64, 5]
        num_classes: 5
        norm: true
        residual: false
        weight: 1.0
        enabled: true
        optimizer:
          optimizer_type: AdamW
          lr: 5.0e-3
          weight_decay: 0.01
          eps: 1.0e-06
          betas: [0.9, 0.999]
          scheduler_type: ReduceLROnPlateau
          mode: min
          factor: 0.5
          patience: 10
          min_lr: 1.0e-05

      - name: space_group # Note: Duplicate task name, this might be an issue or intended for some reason.
        type: CLASSIFICATION
        data_column: Space group (label) # Assuming same column for this duplicate
        dims: [128, 128, 214]
        num_classes: 214
        norm: true
        residual: false
        weight: 1.0
        enabled: true
        optimizer:
          optimizer_type: AdamW
          lr: 5.0e-3
          weight_decay: 0.01
          eps: 1.0e-06
          betas: [0.9, 0.999]
          scheduler_type: ReduceLROnPlateau
          mode: min
          factor: 0.5
          patience: 10
          min_lr: 1.0e-05

      # ExtendRegression tasks
      - name: dos # Note: Duplicate task name, this might be an issue or intended for some reason.
        type: ExtendRegression
        data_column: DOS density (normalized) # Assuming same column for this duplicate
        t_column: DOS energy
        x_dim: [128, 64]
        t_dim: [128, 64]
        t_encoding_method: fourier
        # t_encoding_method: fc
        norm: false
        residual: false
        weight: 1.0
        enabled: true
        optimizer:
          optimizer_type: AdamW
          lr: 5.0e-3
          weight_decay: 0.01
          eps: 1.0e-06
          betas: [0.9, 0.999]
          scheduler_type: ReduceLROnPlateau
          mode: min
          factor: 0.5
          patience: 50
          min_lr: 1.0e-04

      # ExtendRegression tasks
      - name: electrical_resistivity # Note: Duplicate task name, this might be an issue or intended for some reason.
        type: ExtendRegression
        data_column: Electrical resistivity (normalized) # Assuming same column for this duplicate
        t_column: Electrical resistivity (T/K)
        x_dim: [128, 64]
        t_dim: [128, 64]
        t_encoding_method: fourier
        # t_encoding_method: fc
        norm: false
        residual: false
        weight: 1.0
        enabled: true
        optimizer:
          optimizer_type: AdamW
          lr: 5.0e-3
          weight_decay: 0.01
          eps: 1.0e-06
          betas: [0.9, 0.999]
          scheduler_type: ReduceLROnPlateau
          mode: min
          factor: 0.5
          patience: 50
          min_lr: 1.0e-04

      - name: power_factor # Note: Duplicate task name, this might be an issue or intended for some reason.
        type: ExtendRegression
        data_column: Power factor (normalized) # Assuming same column for this duplicate
        t_column: Power factor (T/K)
        x_dim: [128, 64]
        t_dim: [128, 64]
        t_encoding_method: fourier
        # t_encoding_method: fc
        norm: false
        residual: false
        weight: 1.0
        enabled: true
        optimizer:
          optimizer_type: AdamW
          lr: 5.0e-3
          weight_decay: 0.01
          eps: 1.0e-06
          betas: [0.9, 0.999]
          scheduler_type: ReduceLROnPlateau
          mode: min
          factor: 0.5
          patience: 50
          min_lr: 1.0e-04

      - name: seebeck_coefficient # Note: Duplicate task name, this might be an issue or intended for some reason.
        type: ExtendRegression
        data_column: Seebeck coefficient (normalized) # Assuming same column for this duplicate
        t_column: Seebeck coefficient (T/K)
        x_dim: [128, 64]
        t_dim: [128, 64]
        t_encoding_method: fourier
        # t_encoding_method: fc
        norm: false
        residual: false
        weight: 1.0
        enabled: true
        optimizer:
          optimizer_type: AdamW
          lr: 5.0e-3
          weight_decay: 0.01
          eps: 1.0e-06
          betas: [0.9, 0.999]
          scheduler_type: ReduceLROnPlateau
          mode: min
          factor: 0.5
          patience: 50
          min_lr: 1.0e-04

      - name: thermal_conductivity # Note: Duplicate task name, this might be an issue or intended for some reason.
        type: ExtendRegression
        data_column: Thermal conductivity (normalized) # Assuming same column for this duplicate
        t_column: Thermal conductivity (T/K)
        x_dim: [128, 64]
        t_dim: [128, 64]
        t_encoding_method: fourier
        # t_encoding_method: fc
        norm: false
        residual: false
        weight: 1.0
        enabled: true
        optimizer:
          optimizer_type: AdamW
          lr: 5.0e-3
          weight_decay: 0.01
          eps: 1.0e-06
          betas: [0.9, 0.999]
          scheduler_type: ReduceLROnPlateau
          mode: min
          factor: 0.5
          patience: 50
          min_lr: 1.0e-04

      - name: zt # Note: Duplicate task name, this might be an issue or intended for some reason.
        type: ExtendRegression
        data_column: ZT (normalized) # Assuming same column for this duplicate
        t_column: ZT (T/K)
        x_dim: [128, 64]
        t_dim: [128, 64]
        t_encoding_method: fourier
        # t_encoding_method: fc
        norm: false
        residual: false
        weight: 1.0
        enabled: true
        optimizer:
          optimizer_type: AdamW
          lr: 5.0e-3
          weight_decay: 0.01
          eps: 1.0e-06
          betas: [0.9, 0.999]
          scheduler_type: ReduceLROnPlateau
          mode: min
          factor: 0.5
          patience: 50
          min_lr: 1.0e-04

      - name: magnetic_susceptibility # Note: Duplicate task name, this might be an issue or intended for some reason.
        type: ExtendRegression
        data_column: Magnetic susceptibility (normalized) # Assuming same column for this duplicate
        t_column: Magnetic susceptibility (T/K)
        x_dim: [128, 64]
        t_dim: [128, 64]
        t_encoding_method: fourier
        # t_encoding_method: fc
        norm: false
        residual: false
        weight: 1.0
        enabled: true
        optimizer:
          optimizer_type: AdamW
          lr: 5.0e-3
          weight_decay: 0.01
          eps: 1.0e-06
          betas: [0.9, 0.999]
          scheduler_type: ReduceLROnPlateau
          mode: min
          factor: 0.5
          patience: 50
          min_lr: 1.0e-04

    shared_block_optimizer:
      optimizer_type: AdamW
      lr: 5.0e-3
      weight_decay: 0.01
      eps: 1.0e-06
      betas: [0.9, 0.999]
      scheduler_type: ReduceLROnPlateau
      mode: min
      factor: 0.1
      patience: 50
      min_lr: 1.0e-05
      monitor: val_final_loss
    with_structure: false
    freeze_shared_encoder: false # Control encoder freezing here
    modality_dropout_p: 0.3
    norm_shared: true
    residual_shared: false
    enable_self_supervised_training: false
    mask_ratio: 0.15
    temperature: 0.07
    loss_weights:
      mfm: 1.0
      contrastive: 1.0
      cross_recon: 1.0
    # lora_rank and lora_alpha are per-task configurations

data:
  class_path: foundation_model.data.CompoundDataModule
  init_args:
    formula_desc_source: /data/foundation_model/data/qc_ac_te_mp_dos_composition_desc_trans_20250615.pd.parquet
    attributes_source: /data/foundation_model/data/qc_ac_te_mp_dos_reformat_20250615.pd.parquet
    # formula_desc_source: /Users/liuchang/projects/foundation_model/data/qc_ac_te_mp_dos_composition_desc_trans_20250615.pd.parquet
    # attributes_source: /Users/liuchang/projects/foundation_model/data/qc_ac_te_mp_dos_reformat_20250615.pd.parquet
    task_configs: ${model.init_args.task_configs}
    batch_size: 64
    num_workers: 0
    val_split: 0.1
    test_split: 0.1
    train_random_seed: 42
    test_random_seed: 24

trainer:
  default_root_dir: ${oc.env:LOG_DIR,results/logs/default_experiment}
  max_epochs: 300
  # devices: auto
  accelerator: auto
  devices: 1
  strategy: "ddp_find_unused_parameters_true"
  enable_progress_bar: true
  fast_dev_run: false
  log_every_n_steps: 50
  logger:
    - class_path: lightning.pytorch.loggers.CSVLogger
      init_args:
        save_dir: ${oc.env:LOG_DIR,results/logs/default_experiment}
        name: csv_logs
    - class_path: lightning.pytorch.loggers.TensorBoardLogger
      init_args:
        save_dir: ${oc.env:LOG_DIR,results/logs/default_experiment}
        name: tensorboard_logs
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        dirpath: ${oc.env:CKPT_DIR,results/logs/default_experiment}
        filename: model-{epoch:02d}-{val_final_loss:.4f}-{step}
        save_weights_only: false
        monitor: val_final_loss
        mode: min
        save_top_k: 3
        save_last: true
        verbose: true
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: val_final_loss
        patience: 20
        mode: min
        verbose: true
