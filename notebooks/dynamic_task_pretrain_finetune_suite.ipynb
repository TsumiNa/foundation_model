{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain & PI Finetuning Suite\n",
    "\n",
    "This notebook orchestrates 20 randomized incremental pretrain runs on non-PI polymers followed by PI-property finetuning with a frozen shared encoder. It combines the continual-task recipes from `dynamic_task_finetuning_demo.ipynb` and `dynamic_task_incremental_finetuning.ipynb`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "\n",
    "- **Descriptors**: `data/amorphous_polymer_FFDescriptor_20250730.parquet`\n",
    "- **Non-PI properties**: `data/amorphous_polymer_non_PI_properties_20250730.parquet`\n",
    "- **PI properties**: `data/amorphous_polymer_PI_properties_20250730.parquet`\n",
    "- Pretrain tasks: 15 properties (density through thermal_diffusivity) sampled in random order per run\n",
    "- PI finetune tasks: density, Rg, r2, self-diffusion, Cp, Cv, linear_expansion, refractive_index, tg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:22:25.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__init__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mLoguru logger initialized for foundation_model package.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger, TensorBoardLogger\n",
    "\n",
    "from foundation_model.data.datamodule import CompoundDataModule\n",
    "from foundation_model.models.flexible_multi_task_model import FlexibleMultiTaskModel\n",
    "from foundation_model.models.model_config import OptimizerConfig, RegressionTaskConfig, TaskType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../data\")\n",
    "DESCRIPTOR_PATH = DATA_DIR / \"amorphous_polymer_FFDescriptor_20250730.parquet\"\n",
    "NON_PI_PATH = DATA_DIR / \"amorphous_polymer_non_PI_properties_20250730.parquet\"\n",
    "PI_PATH = DATA_DIR / \"amorphous_polymer_PI_properties_20250730.parquet\"\n",
    "SCALER_PATH = DATA_DIR / \"amorphous_polymer_properties_scaler_20250730.pkl.z\"\n",
    "\n",
    "USE_NORMALIZED_TARGETS = False\n",
    "ALL_TASK_NAMES = [\n",
    "    \"density\",\n",
    "    \"Rg\",\n",
    "    \"r2\",\n",
    "    # \"self-diffusion\",\n",
    "    # \"Cp\",\n",
    "    # \"Cv\",\n",
    "    # \"bulk_modulus\",\n",
    "    # \"volume_expansion\",\n",
    "    # \"linear_expansion\",\n",
    "    # \"static_dielectric_const\",\n",
    "    # \"dielectric_const_dc\",\n",
    "    # \"refractive_index\",\n",
    "    # \"tg\",\n",
    "    # \"thermal_conductivity\",\n",
    "    # \"thermal_diffusivity\",\n",
    "]\n",
    "PI_TASK_NAMES = [\n",
    "    \"density\",\n",
    "    \"Rg\",\n",
    "    \"r2\",\n",
    "    # \"self-diffusion\",\n",
    "    # \"Cp\",\n",
    "    # \"Cv\",\n",
    "    # \"linear_expansion\",\n",
    "    # \"refractive_index\",\n",
    "    # \"tg\",\n",
    "]\n",
    "TARGET_COLUMNS = {\n",
    "    name: f\"{name}{'(normalized)' if USE_NORMALIZED_TARGETS else ''}\"\n",
    "    for name in ALL_TASK_NAMES\n",
    "}\n",
    "\n",
    "SHARED_BLOCK_DIMS = [190, 256, 128]\n",
    "HEAD_HIDDEN = 64\n",
    "ARTIFACT_ROOT = Path(\"../artifacts/polymers_pretrain_finetune_runs\")\n",
    "ARTIFACT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "NUM_PRETRAIN_RUNS = 2  # Number of different task orders to try\n",
    "PRETRAIN_MAX_EPOCHS = 10  # Max epochs for pretraining\n",
    "FINETUNE_MAX_EPOCHS = 10  # Max epochs for finetuning each task\n",
    "BATCH_SIZE = 256\n",
    "NUM_WORKERS = 0\n",
    "LOG_EVERY_N_STEPS = 50\n",
    "RANDOM_SEED_BASE = 1729\n",
    "\n",
    "PRETRAIN_SAMPLE = None  # Set to an int for smoke tests\n",
    "PI_SAMPLE = None  # Set to an int for smoke tests\n",
    "\n",
    "PROPERTY_SCALERS: dict[str, Any] = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain feature matrix: (71725, 190)\n",
      "Pretrain target matrix: (71725, 3)\n",
      "PI feature matrix: (1083, 190)\n",
      "PI target matrix: (1083, 3)\n"
     ]
    }
   ],
   "source": [
    "descriptor_df = pd.read_parquet(DESCRIPTOR_PATH)\n",
    "non_pi_df = pd.read_parquet(NON_PI_PATH)\n",
    "pi_df = pd.read_parquet(PI_PATH)\n",
    "\n",
    "if USE_NORMALIZED_TARGETS:\n",
    "    if not SCALER_PATH.exists():\n",
    "        raise FileNotFoundError(f\"Missing scaler file: {SCALER_PATH}\")\n",
    "    PROPERTY_SCALERS = joblib.load(SCALER_PATH)\n",
    "    missing_scalers = [name for name in ALL_TASK_NAMES if name not in PROPERTY_SCALERS]\n",
    "    if missing_scalers:\n",
    "        raise KeyError(f\"Scaler missing entries for: {missing_scalers}\")\n",
    "else:\n",
    "    PROPERTY_SCALERS = {}\n",
    "\n",
    "missing_non_pi = [TARGET_COLUMNS[name] for name in ALL_TASK_NAMES if TARGET_COLUMNS[name] not in non_pi_df.columns]\n",
    "if missing_non_pi:\n",
    "    raise KeyError(f\"Non-PI table missing columns: {missing_non_pi}\")\n",
    "\n",
    "missing_pi = [TARGET_COLUMNS[name] for name in PI_TASK_NAMES if TARGET_COLUMNS[name] not in pi_df.columns]\n",
    "if missing_pi:\n",
    "    raise KeyError(f\"PI table missing columns: {missing_pi}\")\n",
    "\n",
    "common_non_pi_index = descriptor_df.index.intersection(non_pi_df.index)\n",
    "pretrain_features = descriptor_df.loc[common_non_pi_index]\n",
    "pretrain_targets = non_pi_df.loc[common_non_pi_index, [TARGET_COLUMNS[name] for name in ALL_TASK_NAMES]]\n",
    "\n",
    "if PRETRAIN_SAMPLE is not None and PRETRAIN_SAMPLE < len(pretrain_features):\n",
    "    pretrain_features = pretrain_features.sample(n=PRETRAIN_SAMPLE, random_state=42)\n",
    "    pretrain_targets = pretrain_targets.loc[pretrain_features.index]\n",
    "\n",
    "common_pi_index = descriptor_df.index.intersection(pi_df.index)\n",
    "pi_features = descriptor_df.loc[common_pi_index]\n",
    "pi_targets = pi_df.loc[common_pi_index, [TARGET_COLUMNS[name] for name in PI_TASK_NAMES]]\n",
    "\n",
    "if PI_SAMPLE is not None and PI_SAMPLE < len(pi_features):\n",
    "    pi_features = pi_features.sample(n=PI_SAMPLE, random_state=13)\n",
    "    pi_targets = pi_targets.loc[pi_features.index]\n",
    "\n",
    "print(f\"Pretrain feature matrix: {pretrain_features.shape}\")\n",
    "print(f\"Pretrain target matrix: {pretrain_targets.shape}\")\n",
    "print(f\"PI feature matrix: {pi_features.shape}\")\n",
    "print(f\"PI target matrix: {pi_targets.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_slug(name: str) -> str:\n",
    "    slug = re.sub(r\"[^a-z0-9]+\", \"_\", name.lower()).strip(\"_\")\n",
    "    return slug or \"task\"\n",
    "\n",
    "def maybe_inverse_transform(property_name: str, values: np.ndarray) -> np.ndarray:\n",
    "    if not USE_NORMALIZED_TARGETS:\n",
    "        return values\n",
    "    scaler = PROPERTY_SCALERS.get(property_name)\n",
    "    if scaler is None:\n",
    "        raise KeyError(f\"Scaler not found for property '{property_name}'\")\n",
    "    reshaped = values.reshape(-1, 1)\n",
    "    restored = scaler.inverse_transform(reshaped)\n",
    "    return np.asarray(restored).reshape(-1)\n",
    "\n",
    "def build_regression_task(name: str, column: str) -> RegressionTaskConfig:\n",
    "    return RegressionTaskConfig(\n",
    "        name=name,\n",
    "        data_column=column,\n",
    "        dims=[SHARED_BLOCK_DIMS[-1], HEAD_HIDDEN, 1],\n",
    "        norm=True,\n",
    "        residual=False,\n",
    "    )\n",
    "\n",
    "def make_pretrain_task_configs(task_names: list[str]) -> list[RegressionTaskConfig]:\n",
    "    return [build_regression_task(name, TARGET_COLUMNS[name]) for name in task_names]\n",
    "\n",
    "def make_pi_task_config(task_name: str) -> RegressionTaskConfig:\n",
    "    return build_regression_task(task_name, TARGET_COLUMNS[task_name])\n",
    "\n",
    "def build_pretrain_datamodule(task_names: list[str], *, batch_size: int = BATCH_SIZE) -> CompoundDataModule:\n",
    "    stage_targets = pretrain_targets.loc[:, [TARGET_COLUMNS[name] for name in task_names]]\n",
    "    return CompoundDataModule(\n",
    "        formula_desc_source=pretrain_features,\n",
    "        attributes_source=stage_targets,\n",
    "        task_configs=make_pretrain_task_configs(task_names),\n",
    "        batch_size=batch_size,\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n",
    "\n",
    "def build_pi_datamodule(task_name: str, *, batch_size: int = BATCH_SIZE) -> CompoundDataModule:\n",
    "    target_frame = pi_targets.loc[:, [TARGET_COLUMNS[task_name]]]\n",
    "    task_config = make_pi_task_config(task_name)\n",
    "    return CompoundDataModule(\n",
    "        formula_desc_source=pi_features,\n",
    "        attributes_source=target_frame,\n",
    "        task_configs=[task_config],\n",
    "        batch_size=batch_size,\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n",
    "\n",
    "def plot_test_predictions(\n",
    "    *,\n",
    "    model: FlexibleMultiTaskModel,\n",
    "    datamodule: CompoundDataModule,\n",
    "    phase: str,\n",
    "    run_id: int,\n",
    "    stage_num: int,\n",
    "    stage_tasks: list[str],\n",
    "    new_task_name: str,\n",
    "    output_dir: Path | str,\n",
    ") -> None:\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    metrics_path = output_dir / \"metrics.json\"\n",
    "    predictions_path = output_dir / \"predictions.parquet\"\n",
    "    task_order_path = output_dir / \"tasks.txt\"\n",
    "    task_order_path.write_text(\" -> \".join(stage_tasks) + \"\", encoding=\"utf-8\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        device = \"mps\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "\n",
    "    datamodule.setup(stage=\"test\")\n",
    "    test_loader = datamodule.test_dataloader()\n",
    "    if test_loader is None:\n",
    "        raise RuntimeError(f\"{phase} stage {stage_num} has no test dataloader\")\n",
    "\n",
    "    original_device = next(model.parameters()).device\n",
    "    was_training = model.training\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    aggregated: dict[str, dict[str, list[torch.Tensor]]] = {}\n",
    "    prediction_rows: list[dict[str, float | int | str]] = []\n",
    "    per_task_counts: dict[str, int] = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            x, y_dict, mask_dict, t_sequences = batch\n",
    "            x = x.to(device)\n",
    "            preds = model(x, t_sequences)\n",
    "\n",
    "            for name, pred_tensor in preds.items():\n",
    "                if name not in y_dict:\n",
    "                    continue\n",
    "\n",
    "                target_tensor = y_dict[name]\n",
    "                mask_tensor = mask_dict.get(name)\n",
    "\n",
    "                if isinstance(target_tensor, list):\n",
    "                    target_flat = torch.cat([t.detach().cpu().reshape(-1) for t in target_tensor])\n",
    "                else:\n",
    "                    target_flat = target_tensor.detach().cpu().reshape(-1)\n",
    "\n",
    "                pred_flat = pred_tensor.detach().cpu().reshape(-1)\n",
    "\n",
    "                if mask_tensor is not None:\n",
    "                    if isinstance(mask_tensor, list):\n",
    "                        mask_flat = torch.cat([m.detach().cpu().reshape(-1) for m in mask_tensor])\n",
    "                    else:\n",
    "                        mask_flat = mask_tensor.detach().cpu().reshape(-1)\n",
    "                    mask_flat = mask_flat.bool()\n",
    "                    target_flat = target_flat[mask_flat]\n",
    "                    pred_flat = pred_flat[mask_flat]\n",
    "\n",
    "                if target_flat.numel() == 0:\n",
    "                    continue\n",
    "\n",
    "                target_np = target_flat.numpy()\n",
    "                pred_np = pred_flat.numpy()\n",
    "                target_np = maybe_inverse_transform(name, target_np)\n",
    "                pred_np = maybe_inverse_transform(name, pred_np)\n",
    "\n",
    "                entry = aggregated.setdefault(name, {\"preds\": [], \"targets\": []})\n",
    "                entry[\"preds\"].append(torch.from_numpy(pred_np.astype(np.float32)))\n",
    "                entry[\"targets\"].append(torch.from_numpy(target_np.astype(np.float32)))\n",
    "\n",
    "                start_idx = per_task_counts.get(name, 0)\n",
    "                for offset, (actual_val, pred_val) in enumerate(zip(target_np.tolist(), pred_np.tolist())):\n",
    "                    prediction_rows.append(\n",
    "                        {\n",
    "                            \"run\": run_id,\n",
    "                            \"phase\": phase,\n",
    "                            \"stage\": stage_num,\n",
    "                            \"task\": name,\n",
    "                            \"sample_index\": start_idx + offset,\n",
    "                            \"actual\": actual_val,\n",
    "                            \"predicted\": pred_val,\n",
    "                        }\n",
    "                    )\n",
    "                per_task_counts[name] = start_idx + len(target_np)\n",
    "\n",
    "    if not aggregated:\n",
    "        print(f\"No predictions to log for run {run_id} stage {stage_num} ({phase}).\")\n",
    "        model.to(original_device)\n",
    "        if was_training:\n",
    "            model.train()\n",
    "        return\n",
    "\n",
    "    ordered_items = [(name, aggregated[name]) for name in stage_tasks if name in aggregated]\n",
    "\n",
    "    metrics: dict[str, dict[str, float | int | None]] = {}\n",
    "    num_tasks = len(ordered_items)\n",
    "    cols = 2 if num_tasks > 1 else 1\n",
    "    rows = math.ceil(num_tasks / cols)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4.5, rows * 4.5))\n",
    "    if hasattr(axes, \"flat\"):\n",
    "        axes_list = list(axes.flat)\n",
    "    else:\n",
    "        axes_list = [axes]\n",
    "\n",
    "    for ax, (name, data) in zip(axes_list, ordered_items):\n",
    "        preds = torch.cat(data[\"preds\"]).numpy()\n",
    "        targets = torch.cat(data[\"targets\"]).numpy()\n",
    "        diff = preds - targets\n",
    "        mae = float(np.mean(np.abs(diff)))\n",
    "        mse = float(np.mean(diff ** 2))\n",
    "        rmse = float(np.sqrt(np.mean(diff ** 2)))\n",
    "        ss_tot = float(np.sum((targets - np.mean(targets)) ** 2))\n",
    "        ss_res = float(np.sum(diff ** 2))\n",
    "        r2_value = 1.0 - ss_res / ss_tot if ss_tot > 0 else None\n",
    "\n",
    "        metrics[name] = {\n",
    "            \"samples\": int(targets.size),\n",
    "            \"mae\": mae,\n",
    "            \"mse\": mse,\n",
    "            \"rmse\": rmse,\n",
    "            \"r2\": r2_value,\n",
    "        }\n",
    "\n",
    "        lo = float(min(preds.min(), targets.min()))\n",
    "        hi = float(max(preds.max(), targets.max()))\n",
    "        buffer = 0.05 * (hi - lo) if hi > lo else 0.1\n",
    "        lo -= buffer\n",
    "        hi += buffer\n",
    "\n",
    "        ax.scatter(targets, preds, s=12, alpha=0.6, edgecolors=\"none\")\n",
    "        ax.plot([lo, hi], [lo, hi], \"--\", color=\"tab:red\", linewidth=1)\n",
    "        annotation = rf\"MAE: {mae:.3f} $R^2$: {r2_value:.3f}\" if r2_value is not None else f\"MAE: {mae:.3f}\"\n",
    "        ax.text(\n",
    "            0.05,\n",
    "            0.95,\n",
    "            annotation,\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=10,\n",
    "            verticalalignment=\"top\",\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.6),\n",
    "        )\n",
    "        ax.set_xlim(lo, hi)\n",
    "        ax.set_ylim(lo, hi)\n",
    "        ax.set_xlabel(\"Actual\")\n",
    "        ax.set_ylabel(\"Predicted\")\n",
    "        ax.set_title(f\"{phase.title()} Stage {stage_num}: {name}\")\n",
    "        ax.grid(alpha=0.2)\n",
    "        ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "    for ax in axes_list[len(ordered_items):]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(output_dir / f\"{phase}_stage{stage_num:02d}_overview.png\", dpi=180)\n",
    "    plt.close(fig)\n",
    "\n",
    "    for name, data in ordered_items:\n",
    "        preds = torch.cat(data[\"preds\"]).numpy()\n",
    "        targets = torch.cat(data[\"targets\"]).numpy()\n",
    "        lo = float(min(preds.min(), targets.min()))\n",
    "        hi = float(max(preds.max(), targets.max()))\n",
    "        buffer = 0.05 * (hi - lo) if hi > lo else 0.1\n",
    "        lo -= buffer\n",
    "        hi += buffer\n",
    "\n",
    "        fig_single, ax_single = plt.subplots(figsize=(5, 5))\n",
    "        ax_single.scatter(targets, preds, s=12, alpha=0.6, edgecolors=\"none\")\n",
    "        ax_single.plot([lo, hi], [lo, hi], \"--\", color=\"tab:red\", linewidth=1)\n",
    "        ax_single.set_xlim(lo, hi)\n",
    "        ax_single.set_ylim(lo, hi)\n",
    "        ax_single.set_xlabel(\"Actual\")\n",
    "        ax_single.set_ylabel(\"Predicted\")\n",
    "        ax_single.set_title(f\"{phase.title()} Stage {stage_num}: {name}\")\n",
    "        ax_single.grid(alpha=0.2)\n",
    "        ax_single.set_aspect(\"equal\", adjustable=\"box\")\n",
    "        fig_single.tight_layout()\n",
    "        ax_file = output_dir / f\"{safe_slug(name)}_pred.png\"\n",
    "        fig_single.savefig(ax_file, dpi=180)\n",
    "        plt.close(fig_single)\n",
    "\n",
    "    metrics_payload = {\n",
    "        \"run_id\": run_id,\n",
    "        \"phase\": phase,\n",
    "        \"stage\": stage_num,\n",
    "        \"new_task\": new_task_name,\n",
    "        \"task_sequence\": list(stage_tasks),\n",
    "        \"metrics\": metrics,\n",
    "    }\n",
    "\n",
    "    if prediction_rows:\n",
    "        pd.DataFrame(prediction_rows).to_parquet(predictions_path, index=False)\n",
    "        print(f\"Saved predictions to {predictions_path}\")\n",
    "\n",
    "    with open(metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metrics_payload, f, indent=2)\n",
    "    print(f\"Saved metrics to {metrics_path}\")\n",
    "\n",
    "    model.to(original_device)\n",
    "    if was_training:\n",
    "        model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.serialization.add_safe_globals([RegressionTaskConfig, TaskType, OptimizerConfig])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrain & Finetune Workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:22:57.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mInitializing CompoundDataModule...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1m--- Loading Data ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'formula_desc' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'formula_desc'. Shape: (71725, 190)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mInitial loaded formula_df length: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1mFormula_df length after initial dropna: 71725. This index is now the master reference.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'attributes' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'attributes'. Shape: (71725, 1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1mInitial loaded attributes_df length: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--- Aligning DataFrames by formula_df index (master_index length: 71725) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mLength after aligning formula_df and attributes_df: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m279\u001b[0m - \u001b[1mDataModule initialized with 1 task configurations.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mLearnable task uncertainty (task_log_sigmas) is ENABLED.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mInitializing FlexibleMultiTaskModel...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mRegistered Task Heads:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m     name       type  enabled\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m  density REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[1mFlexibleMultiTaskModel Structure:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  FlexibleMultiTaskModel(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_log_sigmas): ParameterDict(  (density): Parameter containing: [torch.FloatTensor of size ])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (encoder): FoundationEncoder(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_heads): ModuleDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (density): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (disabled_task_heads): ModuleDict()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mFlexibleMultiTaskModel initialization complete.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m2025-10-31 09:22:57.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: TrainerFn.FITTING ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (71725) into train_val (64552) and test (7173) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (64552) into train (57379) and val (7173) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=57379, Validation=7173, Test=7173\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m462\u001b[0m - \u001b[1m--- Creating 'fit' stage datasets (train/val) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m464\u001b[0m - \u001b[1mCreating train_dataset with 57379 samples.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "Starting run01\n",
      "Task order: ['density', 'Rg', 'r2']\n",
      "====================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:22:57.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[train_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[train_dataset] Final x_formula shape: torch.Size([57379, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[train_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m483\u001b[0m - \u001b[1mCreating val_dataset with 7173 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[val_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[val_dataset] Final x_formula shape: torch.Size([7173, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[val_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:57.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'TrainerFn.FITTING' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:22:58.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36mconfigure_optimizers\u001b[0m:\u001b[36m1037\u001b[0m - \u001b[1mAdded 1 task_log_sigmas parameters to the main optimizer.\u001b[0m\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:317: The lr scheduler dict contains the key(s) ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n",
      "\n",
      "  | Name                | Type              | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | task_log_sigmas     | ParameterDict     | 1      | train\n",
      "1 | encoder             | FoundationEncoder | 99.1 K | train\n",
      "2 | shared              | LinearBlock       | 82.6 K | train\n",
      "3 | deposit             | Sequential        | 16.5 K | train\n",
      "4 | task_heads          | ModuleDict        | 8.4 K  | train\n",
      "5 | disabled_task_heads | ModuleDict        | 0      | train\n",
      "------------------------------------------------------------------\n",
      "107 K     Trainable params\n",
      "0         Non-trainable params\n",
      "107 K     Total params\n",
      "0.430     Total estimated model params size (MB)\n",
      "26        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 225/225 [00:01<00:00, 123.87it/s, v_num=0, train_final_loss_step=-1.99, val_final_loss=-2.08, train_final_loss_epoch=-2.05] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 225/225 [00:01<00:00, 122.53it/s, v_num=0, train_final_loss_step=-1.99, val_final_loss=-2.08, train_final_loss_epoch=-2.05]\n",
      "Run run01 stage 1: best checkpoint -> /Users/liuchang/projects/foundation_model/artifacts/polymers_pretrain_finetune_runs/run01/pretrain_stage01_density/checkpoints/density-epoch=09-val_final_loss=-2.0792.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:23:19.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: test ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:19.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:19.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:19.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:19.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (71725) into train_val (64552) and test (7173) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:19.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (64552) into train (57379) and val (7173) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:19.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=57379, Validation=7173, Test=7173\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:19.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m666\u001b[0m - \u001b[1m--- Creating 'test' stage dataset ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:19.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m668\u001b[0m - \u001b[1mCreating test_dataset with 7173 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:19.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[test_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:19.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[test_dataset] Final x_formula shape: torch.Size([7173, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:19.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:19.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[test_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:19.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'test' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:19.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mInitializing CompoundDataModule...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:19.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1m--- Loading Data ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:19.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'formula_desc' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:19.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'formula_desc'. Shape: (71725, 190)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:19.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mInitial loaded formula_df length: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1mFormula_df length after initial dropna: 71725. This index is now the master reference.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'attributes' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'attributes'. Shape: (71725, 2)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1mInitial loaded attributes_df length: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--- Aligning DataFrames by formula_df index (master_index length: 71725) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mLength after aligning formula_df and attributes_df: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m279\u001b[0m - \u001b[1mDataModule initialized with 2 task configurations.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mLearnable task uncertainty (task_log_sigmas) is ENABLED.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mInitializing FlexibleMultiTaskModel...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mRegistered Task Heads:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m     name       type  enabled\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m  density REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[1mFlexibleMultiTaskModel Structure:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  FlexibleMultiTaskModel(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_log_sigmas): ParameterDict(  (density): Parameter containing: [torch.FloatTensor of size ])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (encoder): FoundationEncoder(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_heads): ModuleDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (density): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (disabled_task_heads): ModuleDict()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mFlexibleMultiTaskModel initialization complete.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1384\u001b[0m - \u001b[1mLoaded shared_encoder optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded density task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1406\u001b[0m - \u001b[1mSuccessfully loaded 2 optimizer states from dict format\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1mAdded task 'Rg' (type=REGRESSION, enabled=True).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mActivated tasks during add_task: Rg\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m2025-10-31 09:23:20.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: TrainerFn.FITTING ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (71725) into train_val (64552) and test (7173) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (64552) into train (57379) and val (7173) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=57379, Validation=7173, Test=7173\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m462\u001b[0m - \u001b[1m--- Creating 'fit' stage datasets (train/val) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m464\u001b[0m - \u001b[1mCreating train_dataset with 57379 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[train_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[train_dataset] Final x_formula shape: torch.Size([57379, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to ../artifacts/polymers_pretrain_finetune_runs/run01/pretrain_stage01_density/prediction/predictions.parquet\n",
      "Saved metrics to ../artifacts/polymers_pretrain_finetune_runs/run01/pretrain_stage01_density/prediction/metrics.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:23:20.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[train_dataset] CompoundDataset initialization complete. Processed 2 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m483\u001b[0m - \u001b[1mCreating val_dataset with 7173 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[val_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[val_dataset] Final x_formula shape: torch.Size([7173, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[val_dataset] CompoundDataset initialization complete. Processed 2 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'TrainerFn.FITTING' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:20.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36mconfigure_optimizers\u001b[0m:\u001b[36m1037\u001b[0m - \u001b[1mAdded 2 task_log_sigmas parameters to the main optimizer.\u001b[0m\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:317: The lr scheduler dict contains the key(s) ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n",
      "\n",
      "  | Name                | Type              | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | task_log_sigmas     | ParameterDict     | 2      | train\n",
      "1 | encoder             | FoundationEncoder | 99.1 K | train\n",
      "2 | shared              | LinearBlock       | 82.6 K | train\n",
      "3 | deposit             | Sequential        | 16.5 K | train\n",
      "4 | task_heads          | ModuleDict        | 16.9 K | train\n",
      "5 | disabled_task_heads | ModuleDict        | 0      | train\n",
      "------------------------------------------------------------------\n",
      "115 K     Trainable params\n",
      "0         Non-trainable params\n",
      "115 K     Total params\n",
      "0.464     Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 225/225 [00:02<00:00, 79.18it/s, v_num=0, train_final_loss_step=2.840, val_final_loss=1.270, train_final_loss_epoch=1.320]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 225/225 [00:02<00:00, 78.46it/s, v_num=0, train_final_loss_step=2.840, val_final_loss=1.270, train_final_loss_epoch=1.320]\n",
      "Run run01 stage 2: best checkpoint -> /Users/liuchang/projects/foundation_model/artifacts/polymers_pretrain_finetune_runs/run01/pretrain_stage02_rg/checkpoints/rg-epoch=09-val_final_loss=1.2663.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:23:49.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: test ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (71725) into train_val (64552) and test (7173) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (64552) into train (57379) and val (7173) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=57379, Validation=7173, Test=7173\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m666\u001b[0m - \u001b[1m--- Creating 'test' stage dataset ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m668\u001b[0m - \u001b[1mCreating test_dataset with 7173 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[test_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[test_dataset] Final x_formula shape: torch.Size([7173, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[test_dataset] CompoundDataset initialization complete. Processed 2 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'test' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mInitializing CompoundDataModule...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1m--- Loading Data ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'formula_desc' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'formula_desc'. Shape: (71725, 190)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mInitial loaded formula_df length: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1mFormula_df length after initial dropna: 71725. This index is now the master reference.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'attributes' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'attributes'. Shape: (71725, 3)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1mInitial loaded attributes_df length: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--- Aligning DataFrames by formula_df index (master_index length: 71725) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.386\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m231\u001b[0m - \u001b[33m\u001b[1mattributes_df contains NaN values after reindexing. This is expected if some properties are missing for certain samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mLength after aligning formula_df and attributes_df: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m279\u001b[0m - \u001b[1mDataModule initialized with 3 task configurations.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mLearnable task uncertainty (task_log_sigmas) is ENABLED.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mInitializing FlexibleMultiTaskModel...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mRegistered Task Heads:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m     name       type  enabled\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m  density REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m       Rg REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[1mFlexibleMultiTaskModel Structure:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  FlexibleMultiTaskModel(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_log_sigmas): ParameterDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (density): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (Rg): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (encoder): FoundationEncoder(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_heads): ModuleDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (density): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (Rg): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (disabled_task_heads): ModuleDict()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mFlexibleMultiTaskModel initialization complete.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1384\u001b[0m - \u001b[1mLoaded shared_encoder optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded density task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded Rg task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1406\u001b[0m - \u001b[1mSuccessfully loaded 3 optimizer states from dict format\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1mAdded task 'r2' (type=REGRESSION, enabled=True).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mActivated tasks during add_task: r2\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m2025-10-31 09:23:49.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: TrainerFn.FITTING ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (71725) into train_val (64552) and test (7173) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (64552) into train (57379) and val (7173) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=57379, Validation=7173, Test=7173\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m462\u001b[0m - \u001b[1m--- Creating 'fit' stage datasets (train/val) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m464\u001b[0m - \u001b[1mCreating train_dataset with 57379 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[train_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[train_dataset] Final x_formula shape: torch.Size([57379, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to ../artifacts/polymers_pretrain_finetune_runs/run01/pretrain_stage02_rg/prediction/predictions.parquet\n",
      "Saved metrics to ../artifacts/polymers_pretrain_finetune_runs/run01/pretrain_stage02_rg/prediction/metrics.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:23:49.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'r2' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[train_dataset] CompoundDataset initialization complete. Processed 3 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m483\u001b[0m - \u001b[1mCreating val_dataset with 7173 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[val_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[val_dataset] Final x_formula shape: torch.Size([7173, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'r2' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[val_dataset] CompoundDataset initialization complete. Processed 3 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'TrainerFn.FITTING' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:23:49.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36mconfigure_optimizers\u001b[0m:\u001b[36m1037\u001b[0m - \u001b[1mAdded 3 task_log_sigmas parameters to the main optimizer.\u001b[0m\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:317: The lr scheduler dict contains the key(s) ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n",
      "\n",
      "  | Name                | Type              | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | task_log_sigmas     | ParameterDict     | 3      | train\n",
      "1 | encoder             | FoundationEncoder | 99.1 K | train\n",
      "2 | shared              | LinearBlock       | 82.6 K | train\n",
      "3 | deposit             | Sequential        | 16.5 K | train\n",
      "4 | task_heads          | ModuleDict        | 25.3 K | train\n",
      "5 | disabled_task_heads | ModuleDict        | 0      | train\n",
      "------------------------------------------------------------------\n",
      "124 K     Trainable params\n",
      "0         Non-trainable params\n",
      "124 K     Total params\n",
      "0.498     Total estimated model params size (MB)\n",
      "46        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 225/225 [00:03<00:00, 61.50it/s, v_num=0, train_final_loss_step=131.0, val_final_loss=355.0, train_final_loss_epoch=351.0]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 225/225 [00:03<00:00, 60.98it/s, v_num=0, train_final_loss_step=131.0, val_final_loss=355.0, train_final_loss_epoch=351.0]\n",
      "Run run01 stage 3: best checkpoint -> /Users/liuchang/projects/foundation_model/artifacts/polymers_pretrain_finetune_runs/run01/pretrain_stage03_r2/checkpoints/r2-epoch=09-val_final_loss=354.5392.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:24:27.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: test ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:27.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:27.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:27.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:27.552\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (71725) into train_val (64552) and test (7173) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:27.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (64552) into train (57379) and val (7173) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:27.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=57379, Validation=7173, Test=7173\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:27.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m666\u001b[0m - \u001b[1m--- Creating 'test' stage dataset ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:27.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m668\u001b[0m - \u001b[1mCreating test_dataset with 7173 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:27.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[test_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:27.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[test_dataset] Final x_formula shape: torch.Size([7173, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:27.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:27.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:27.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'r2' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:27.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[test_dataset] CompoundDataset initialization complete. Processed 3 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:27.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'test' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mLearnable task uncertainty (task_log_sigmas) is ENABLED.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mInitializing FlexibleMultiTaskModel...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mRegistered Task Heads:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m     name       type  enabled\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m  density REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m       Rg REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m       r2 REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[1mFlexibleMultiTaskModel Structure:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  FlexibleMultiTaskModel(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_log_sigmas): ParameterDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (density): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (Rg): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (r2): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (encoder): FoundationEncoder(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_heads): ModuleDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (density): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (Rg): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (r2): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (disabled_task_heads): ModuleDict()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mFlexibleMultiTaskModel initialization complete.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded density task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded Rg task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded r2 task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1406\u001b[0m - \u001b[1mSuccessfully loaded 3 optimizer states from dict format\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36mremove_tasks\u001b[0m:\u001b[36m514\u001b[0m - \u001b[1mRemoved tasks: Rg, density, r2\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1mAdded task 'density' (type=REGRESSION, enabled=True).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mActivated tasks during add_task: density\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mInitializing CompoundDataModule...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1m--- Loading Data ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'formula_desc' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'formula_desc'. Shape: (1083, 190)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mInitial loaded formula_df length: 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1mFormula_df length after initial dropna: 1083. This index is now the master reference.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'attributes' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'attributes'. Shape: (1083, 1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1mInitial loaded attributes_df length: 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--- Aligning DataFrames by formula_df index (master_index length: 1083) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mLength after aligning formula_df and attributes_df: 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m279\u001b[0m - \u001b[1mDataModule initialized with 1 task configurations.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m2025-10-31 09:24:28.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: TrainerFn.FITTING ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (1083) into train_val (974) and test (109) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (974) into train (865) and val (109) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=865, Validation=109, Test=109\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m462\u001b[0m - \u001b[1m--- Creating 'fit' stage datasets (train/val) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m464\u001b[0m - \u001b[1mCreating train_dataset with 865 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[train_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[train_dataset] Final x_formula shape: torch.Size([865, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[train_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m483\u001b[0m - \u001b[1mCreating val_dataset with 109 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[val_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[val_dataset] Final x_formula shape: torch.Size([109, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[val_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'TrainerFn.FITTING' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:28.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36mconfigure_optimizers\u001b[0m:\u001b[36m1037\u001b[0m - \u001b[1mAdded 1 task_log_sigmas parameters to the main optimizer.\u001b[0m\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:317: The lr scheduler dict contains the key(s) ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n",
      "\n",
      "  | Name                | Type              | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | task_log_sigmas     | ParameterDict     | 1      | train\n",
      "1 | encoder             | FoundationEncoder | 99.1 K | train\n",
      "2 | shared              | LinearBlock       | 82.6 K | train\n",
      "3 | deposit             | Sequential        | 16.5 K | train\n",
      "4 | task_heads          | ModuleDict        | 8.4 K  | train\n",
      "5 | disabled_task_heads | ModuleDict        | 0      | train\n",
      "------------------------------------------------------------------\n",
      "8.4 K     Trainable params\n",
      "99.1 K    Non-trainable params\n",
      "107 K     Total params\n",
      "0.430     Total estimated model params size (MB)\n",
      "26        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to ../artifacts/polymers_pretrain_finetune_runs/run01/pretrain_stage03_r2/prediction/predictions.parquet\n",
      "Saved metrics to ../artifacts/polymers_pretrain_finetune_runs/run01/pretrain_stage03_r2/prediction/metrics.json\n",
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 100.80it/s, v_num=0, train_final_loss_step=-0.393, val_final_loss=-0.385, train_final_loss_epoch=-0.381]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 72.42it/s, v_num=0, train_final_loss_step=-0.393, val_final_loss=-0.385, train_final_loss_epoch=-0.381] \n",
      "Run run01 finetune density: best checkpoint -> /Users/liuchang/projects/foundation_model/artifacts/polymers_pretrain_finetune_runs/run01/finetune_stage01_density/checkpoints/density-epoch=09-val_final_loss=-0.3851.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:24:29.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: test ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (1083) into train_val (974) and test (109) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (974) into train (865) and val (109) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=865, Validation=109, Test=109\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m666\u001b[0m - \u001b[1m--- Creating 'test' stage dataset ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m668\u001b[0m - \u001b[1mCreating test_dataset with 109 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[test_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[test_dataset] Final x_formula shape: torch.Size([109, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[test_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'test' complete ---\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to ../artifacts/polymers_pretrain_finetune_runs/run01/finetune_stage01_density/prediction/predictions.parquet\n",
      "Saved metrics to ../artifacts/polymers_pretrain_finetune_runs/run01/finetune_stage01_density/prediction/metrics.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:24:29.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mLearnable task uncertainty (task_log_sigmas) is ENABLED.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mInitializing FlexibleMultiTaskModel...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mRegistered Task Heads:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m     name       type  enabled\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m  density REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m       Rg REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m       r2 REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[1mFlexibleMultiTaskModel Structure:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  FlexibleMultiTaskModel(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_log_sigmas): ParameterDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (density): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (Rg): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (r2): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (encoder): FoundationEncoder(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_heads): ModuleDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (density): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (Rg): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (r2): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (disabled_task_heads): ModuleDict()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mFlexibleMultiTaskModel initialization complete.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded density task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded Rg task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded r2 task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1406\u001b[0m - \u001b[1mSuccessfully loaded 3 optimizer states from dict format\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36mremove_tasks\u001b[0m:\u001b[36m514\u001b[0m - \u001b[1mRemoved tasks: Rg, density, r2\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1mAdded task 'Rg' (type=REGRESSION, enabled=True).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mActivated tasks during add_task: Rg\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mInitializing CompoundDataModule...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1m--- Loading Data ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'formula_desc' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'formula_desc'. Shape: (1083, 190)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mInitial loaded formula_df length: 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1mFormula_df length after initial dropna: 1083. This index is now the master reference.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'attributes' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'attributes'. Shape: (1083, 1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1mInitial loaded attributes_df length: 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--- Aligning DataFrames by formula_df index (master_index length: 1083) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mLength after aligning formula_df and attributes_df: 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m279\u001b[0m - \u001b[1mDataModule initialized with 1 task configurations.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m2025-10-31 09:24:29.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: TrainerFn.FITTING ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (1083) into train_val (974) and test (109) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (974) into train (865) and val (109) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=865, Validation=109, Test=109\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m462\u001b[0m - \u001b[1m--- Creating 'fit' stage datasets (train/val) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m464\u001b[0m - \u001b[1mCreating train_dataset with 865 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[train_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[train_dataset] Final x_formula shape: torch.Size([865, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[train_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m483\u001b[0m - \u001b[1mCreating val_dataset with 109 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[val_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[val_dataset] Final x_formula shape: torch.Size([109, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[val_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'TrainerFn.FITTING' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36mconfigure_optimizers\u001b[0m:\u001b[36m1037\u001b[0m - \u001b[1mAdded 1 task_log_sigmas parameters to the main optimizer.\u001b[0m\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:317: The lr scheduler dict contains the key(s) ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n",
      "\n",
      "  | Name                | Type              | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | task_log_sigmas     | ParameterDict     | 1      | train\n",
      "1 | encoder             | FoundationEncoder | 99.1 K | train\n",
      "2 | shared              | LinearBlock       | 82.6 K | train\n",
      "3 | deposit             | Sequential        | 16.5 K | train\n",
      "4 | task_heads          | ModuleDict        | 8.4 K  | train\n",
      "5 | disabled_task_heads | ModuleDict        | 0      | train\n",
      "------------------------------------------------------------------\n",
      "8.4 K     Trainable params\n",
      "99.1 K    Non-trainable params\n",
      "107 K     Total params\n",
      "0.430     Total estimated model params size (MB)\n",
      "26        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 94.75it/s, v_num=0, train_final_loss_step=54.70, val_final_loss=85.00, train_final_loss_epoch=74.80] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 68.32it/s, v_num=0, train_final_loss_step=54.70, val_final_loss=85.00, train_final_loss_epoch=74.80]\n",
      "Run run01 finetune Rg: best checkpoint -> /Users/liuchang/projects/foundation_model/artifacts/polymers_pretrain_finetune_runs/run01/finetune_stage02_rg/checkpoints/rg-epoch=09-val_final_loss=85.0301.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:24:29.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: test ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (1083) into train_val (974) and test (109) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (974) into train (865) and val (109) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=865, Validation=109, Test=109\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m666\u001b[0m - \u001b[1m--- Creating 'test' stage dataset ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m668\u001b[0m - \u001b[1mCreating test_dataset with 109 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[test_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[test_dataset] Final x_formula shape: torch.Size([109, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[test_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:29.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'test' complete ---\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to ../artifacts/polymers_pretrain_finetune_runs/run01/finetune_stage02_rg/prediction/predictions.parquet\n",
      "Saved metrics to ../artifacts/polymers_pretrain_finetune_runs/run01/finetune_stage02_rg/prediction/metrics.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:24:30.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mLearnable task uncertainty (task_log_sigmas) is ENABLED.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mInitializing FlexibleMultiTaskModel...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mRegistered Task Heads:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m     name       type  enabled\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m  density REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m       Rg REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m       r2 REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[1mFlexibleMultiTaskModel Structure:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  FlexibleMultiTaskModel(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_log_sigmas): ParameterDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (density): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (Rg): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (r2): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (encoder): FoundationEncoder(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_heads): ModuleDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (density): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (Rg): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (r2): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (disabled_task_heads): ModuleDict()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mFlexibleMultiTaskModel initialization complete.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded density task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded Rg task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded r2 task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1406\u001b[0m - \u001b[1mSuccessfully loaded 3 optimizer states from dict format\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36mremove_tasks\u001b[0m:\u001b[36m514\u001b[0m - \u001b[1mRemoved tasks: Rg, density, r2\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1mAdded task 'r2' (type=REGRESSION, enabled=True).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mActivated tasks during add_task: r2\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mInitializing CompoundDataModule...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1m--- Loading Data ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'formula_desc' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'formula_desc'. Shape: (1083, 190)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mInitial loaded formula_df length: 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1mFormula_df length after initial dropna: 1083. This index is now the master reference.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'attributes' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'attributes'. Shape: (1083, 1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1mInitial loaded attributes_df length: 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--- Aligning DataFrames by formula_df index (master_index length: 1083) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.117\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m231\u001b[0m - \u001b[33m\u001b[1mattributes_df contains NaN values after reindexing. This is expected if some properties are missing for certain samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.118\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m247\u001b[0m - \u001b[33m\u001b[1mMaster index (from formula_df) reduced from 1083 to 1078 after aligning with attributes_df. Some formula_df entries might not have corresponding attributes_df entries or vice-versa after NaN removal.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mLength after aligning formula_df and attributes_df: 1078\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m279\u001b[0m - \u001b[1mDataModule initialized with 1 task configurations.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m2025-10-31 09:24:30.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: TrainerFn.FITTING ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 1078\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (1078) into train_val (970) and test (108) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (970) into train (862) and val (108) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=862, Validation=108, Test=108\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m462\u001b[0m - \u001b[1m--- Creating 'fit' stage datasets (train/val) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m464\u001b[0m - \u001b[1mCreating train_dataset with 862 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[train_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[train_dataset] Final x_formula shape: torch.Size([862, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'r2' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[train_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m483\u001b[0m - \u001b[1mCreating val_dataset with 108 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[val_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[val_dataset] Final x_formula shape: torch.Size([108, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'r2' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[val_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'TrainerFn.FITTING' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36mconfigure_optimizers\u001b[0m:\u001b[36m1037\u001b[0m - \u001b[1mAdded 1 task_log_sigmas parameters to the main optimizer.\u001b[0m\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:317: The lr scheduler dict contains the key(s) ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n",
      "\n",
      "  | Name                | Type              | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | task_log_sigmas     | ParameterDict     | 1      | train\n",
      "1 | encoder             | FoundationEncoder | 99.1 K | train\n",
      "2 | shared              | LinearBlock       | 82.6 K | train\n",
      "3 | deposit             | Sequential        | 16.5 K | train\n",
      "4 | task_heads          | ModuleDict        | 8.4 K  | train\n",
      "5 | disabled_task_heads | ModuleDict        | 0      | train\n",
      "------------------------------------------------------------------\n",
      "8.4 K     Trainable params\n",
      "99.1 K    Non-trainable params\n",
      "107 K     Total params\n",
      "0.430     Total estimated model params size (MB)\n",
      "26        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 97.29it/s, v_num=0, train_final_loss_step=471.0, val_final_loss=174.0, train_final_loss_epoch=1.09e+3]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 70.58it/s, v_num=0, train_final_loss_step=471.0, val_final_loss=174.0, train_final_loss_epoch=1.09e+3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:24:30.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: test ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 1078\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (1078) into train_val (970) and test (108) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (970) into train (862) and val (108) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=862, Validation=108, Test=108\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m666\u001b[0m - \u001b[1m--- Creating 'test' stage dataset ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m668\u001b[0m - \u001b[1mCreating test_dataset with 108 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[test_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[test_dataset] Final x_formula shape: torch.Size([108, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'r2' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[test_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:30.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'test' complete ---\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run run01 finetune r2: best checkpoint -> /Users/liuchang/projects/foundation_model/artifacts/polymers_pretrain_finetune_runs/run01/finetune_stage03_r2/checkpoints/r2-epoch=09-val_final_loss=174.3855.ckpt\n",
      "Saved predictions to ../artifacts/polymers_pretrain_finetune_runs/run01/finetune_stage03_r2/prediction/predictions.parquet\n",
      "Saved metrics to ../artifacts/polymers_pretrain_finetune_runs/run01/finetune_stage03_r2/prediction/metrics.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:24:31.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mInitializing CompoundDataModule...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1m--- Loading Data ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'formula_desc' data.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "Starting run02\n",
      "Task order: ['Rg', 'density', 'r2']\n",
      "====================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:24:31.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'formula_desc'. Shape: (71725, 190)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mInitial loaded formula_df length: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1mFormula_df length after initial dropna: 71725. This index is now the master reference.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'attributes' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'attributes'. Shape: (71725, 1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1mInitial loaded attributes_df length: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--- Aligning DataFrames by formula_df index (master_index length: 71725) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mLength after aligning formula_df and attributes_df: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m279\u001b[0m - \u001b[1mDataModule initialized with 1 task configurations.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mLearnable task uncertainty (task_log_sigmas) is ENABLED.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mInitializing FlexibleMultiTaskModel...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mRegistered Task Heads:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m  name       type  enabled\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m    Rg REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[1mFlexibleMultiTaskModel Structure:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  FlexibleMultiTaskModel(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_log_sigmas): ParameterDict(  (Rg): Parameter containing: [torch.FloatTensor of size ])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (encoder): FoundationEncoder(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_heads): ModuleDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (Rg): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (disabled_task_heads): ModuleDict()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mFlexibleMultiTaskModel initialization complete.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m2025-10-31 09:24:31.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: TrainerFn.FITTING ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (71725) into train_val (64552) and test (7173) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (64552) into train (57379) and val (7173) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=57379, Validation=7173, Test=7173\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m462\u001b[0m - \u001b[1m--- Creating 'fit' stage datasets (train/val) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m464\u001b[0m - \u001b[1mCreating train_dataset with 57379 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[train_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[train_dataset] Final x_formula shape: torch.Size([57379, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.164\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[train_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m483\u001b[0m - \u001b[1mCreating val_dataset with 7173 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[val_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[val_dataset] Final x_formula shape: torch.Size([7173, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[val_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'TrainerFn.FITTING' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:31.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36mconfigure_optimizers\u001b[0m:\u001b[36m1037\u001b[0m - \u001b[1mAdded 1 task_log_sigmas parameters to the main optimizer.\u001b[0m\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:317: The lr scheduler dict contains the key(s) ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n",
      "\n",
      "  | Name                | Type              | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | task_log_sigmas     | ParameterDict     | 1      | train\n",
      "1 | encoder             | FoundationEncoder | 99.1 K | train\n",
      "2 | shared              | LinearBlock       | 82.6 K | train\n",
      "3 | deposit             | Sequential        | 16.5 K | train\n",
      "4 | task_heads          | ModuleDict        | 8.4 K  | train\n",
      "5 | disabled_task_heads | ModuleDict        | 0      | train\n",
      "------------------------------------------------------------------\n",
      "107 K     Trainable params\n",
      "0         Non-trainable params\n",
      "107 K     Total params\n",
      "0.430     Total estimated model params size (MB)\n",
      "26        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 225/225 [00:02<00:00, 111.97it/s, v_num=0, train_final_loss_step=12.20, val_final_loss=4.400, train_final_loss_epoch=4.450]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 225/225 [00:02<00:00, 110.83it/s, v_num=0, train_final_loss_step=12.20, val_final_loss=4.400, train_final_loss_epoch=4.450]\n",
      "Run run02 stage 1: best checkpoint -> /Users/liuchang/projects/foundation_model/artifacts/polymers_pretrain_finetune_runs/run02/pretrain_stage01_rg/checkpoints/rg-epoch=09-val_final_loss=4.4016.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:24:51.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: test ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (71725) into train_val (64552) and test (7173) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (64552) into train (57379) and val (7173) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=57379, Validation=7173, Test=7173\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m666\u001b[0m - \u001b[1m--- Creating 'test' stage dataset ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m668\u001b[0m - \u001b[1mCreating test_dataset with 7173 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[test_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[test_dataset] Final x_formula shape: torch.Size([7173, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[test_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'test' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mInitializing CompoundDataModule...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1m--- Loading Data ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'formula_desc' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'formula_desc'. Shape: (71725, 190)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mInitial loaded formula_df length: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1mFormula_df length after initial dropna: 71725. This index is now the master reference.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'attributes' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'attributes'. Shape: (71725, 2)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1mInitial loaded attributes_df length: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--- Aligning DataFrames by formula_df index (master_index length: 71725) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mLength after aligning formula_df and attributes_df: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m279\u001b[0m - \u001b[1mDataModule initialized with 2 task configurations.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mLearnable task uncertainty (task_log_sigmas) is ENABLED.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mInitializing FlexibleMultiTaskModel...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mRegistered Task Heads:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m  name       type  enabled\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m    Rg REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[1mFlexibleMultiTaskModel Structure:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  FlexibleMultiTaskModel(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_log_sigmas): ParameterDict(  (Rg): Parameter containing: [torch.FloatTensor of size ])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (encoder): FoundationEncoder(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_heads): ModuleDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (Rg): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (disabled_task_heads): ModuleDict()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mFlexibleMultiTaskModel initialization complete.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1384\u001b[0m - \u001b[1mLoaded shared_encoder optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded Rg task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1406\u001b[0m - \u001b[1mSuccessfully loaded 2 optimizer states from dict format\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1mAdded task 'density' (type=REGRESSION, enabled=True).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mActivated tasks during add_task: density\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m2025-10-31 09:24:51.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: TrainerFn.FITTING ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (71725) into train_val (64552) and test (7173) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (64552) into train (57379) and val (7173) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=57379, Validation=7173, Test=7173\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m462\u001b[0m - \u001b[1m--- Creating 'fit' stage datasets (train/val) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m464\u001b[0m - \u001b[1mCreating train_dataset with 57379 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[train_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[train_dataset] Final x_formula shape: torch.Size([57379, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to ../artifacts/polymers_pretrain_finetune_runs/run02/pretrain_stage01_rg/prediction/predictions.parquet\n",
      "Saved metrics to ../artifacts/polymers_pretrain_finetune_runs/run02/pretrain_stage01_rg/prediction/metrics.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:24:51.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[train_dataset] CompoundDataset initialization complete. Processed 2 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m483\u001b[0m - \u001b[1mCreating val_dataset with 7173 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[val_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[val_dataset] Final x_formula shape: torch.Size([7173, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[val_dataset] CompoundDataset initialization complete. Processed 2 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'TrainerFn.FITTING' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:24:51.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36mconfigure_optimizers\u001b[0m:\u001b[36m1037\u001b[0m - \u001b[1mAdded 2 task_log_sigmas parameters to the main optimizer.\u001b[0m\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:317: The lr scheduler dict contains the key(s) ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n",
      "\n",
      "  | Name                | Type              | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | task_log_sigmas     | ParameterDict     | 2      | train\n",
      "1 | encoder             | FoundationEncoder | 99.1 K | train\n",
      "2 | shared              | LinearBlock       | 82.6 K | train\n",
      "3 | deposit             | Sequential        | 16.5 K | train\n",
      "4 | task_heads          | ModuleDict        | 16.9 K | train\n",
      "5 | disabled_task_heads | ModuleDict        | 0      | train\n",
      "------------------------------------------------------------------\n",
      "115 K     Trainable params\n",
      "0         Non-trainable params\n",
      "115 K     Total params\n",
      "0.464     Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 225/225 [00:02<00:00, 79.57it/s, v_num=0, train_final_loss_step=1.950, val_final_loss=2.040, train_final_loss_epoch=2.010]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 225/225 [00:02<00:00, 78.84it/s, v_num=0, train_final_loss_step=1.950, val_final_loss=2.040, train_final_loss_epoch=2.010]\n",
      "Run run02 stage 2: best checkpoint -> /Users/liuchang/projects/foundation_model/artifacts/polymers_pretrain_finetune_runs/run02/pretrain_stage02_density/checkpoints/density-epoch=09-val_final_loss=2.0384.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:25:20.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: test ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (71725) into train_val (64552) and test (7173) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (64552) into train (57379) and val (7173) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=57379, Validation=7173, Test=7173\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m666\u001b[0m - \u001b[1m--- Creating 'test' stage dataset ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m668\u001b[0m - \u001b[1mCreating test_dataset with 7173 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[test_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[test_dataset] Final x_formula shape: torch.Size([7173, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[test_dataset] CompoundDataset initialization complete. Processed 2 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'test' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mInitializing CompoundDataModule...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1m--- Loading Data ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'formula_desc' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'formula_desc'. Shape: (71725, 190)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mInitial loaded formula_df length: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1mFormula_df length after initial dropna: 71725. This index is now the master reference.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'attributes' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'attributes'. Shape: (71725, 3)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1mInitial loaded attributes_df length: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--- Aligning DataFrames by formula_df index (master_index length: 71725) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.559\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m231\u001b[0m - \u001b[33m\u001b[1mattributes_df contains NaN values after reindexing. This is expected if some properties are missing for certain samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mLength after aligning formula_df and attributes_df: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m279\u001b[0m - \u001b[1mDataModule initialized with 3 task configurations.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mLearnable task uncertainty (task_log_sigmas) is ENABLED.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mInitializing FlexibleMultiTaskModel...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mRegistered Task Heads:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m     name       type  enabled\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m       Rg REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m  density REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[1mFlexibleMultiTaskModel Structure:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  FlexibleMultiTaskModel(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_log_sigmas): ParameterDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (Rg): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (density): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (encoder): FoundationEncoder(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_heads): ModuleDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (Rg): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (density): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (disabled_task_heads): ModuleDict()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mFlexibleMultiTaskModel initialization complete.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1384\u001b[0m - \u001b[1mLoaded shared_encoder optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded Rg task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded density task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1406\u001b[0m - \u001b[1mSuccessfully loaded 3 optimizer states from dict format\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1mAdded task 'r2' (type=REGRESSION, enabled=True).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mActivated tasks during add_task: r2\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m2025-10-31 09:25:20.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: TrainerFn.FITTING ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (71725) into train_val (64552) and test (7173) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (64552) into train (57379) and val (7173) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=57379, Validation=7173, Test=7173\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m462\u001b[0m - \u001b[1m--- Creating 'fit' stage datasets (train/val) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m464\u001b[0m - \u001b[1mCreating train_dataset with 57379 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[train_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[train_dataset] Final x_formula shape: torch.Size([57379, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to ../artifacts/polymers_pretrain_finetune_runs/run02/pretrain_stage02_density/prediction/predictions.parquet\n",
      "Saved metrics to ../artifacts/polymers_pretrain_finetune_runs/run02/pretrain_stage02_density/prediction/metrics.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:25:20.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'r2' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[train_dataset] CompoundDataset initialization complete. Processed 3 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m483\u001b[0m - \u001b[1mCreating val_dataset with 7173 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[val_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[val_dataset] Final x_formula shape: torch.Size([7173, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:20.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'r2' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:21.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[val_dataset] CompoundDataset initialization complete. Processed 3 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:21.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'TrainerFn.FITTING' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:21.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36mconfigure_optimizers\u001b[0m:\u001b[36m1037\u001b[0m - \u001b[1mAdded 3 task_log_sigmas parameters to the main optimizer.\u001b[0m\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:317: The lr scheduler dict contains the key(s) ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n",
      "\n",
      "  | Name                | Type              | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | task_log_sigmas     | ParameterDict     | 3      | train\n",
      "1 | encoder             | FoundationEncoder | 99.1 K | train\n",
      "2 | shared              | LinearBlock       | 82.6 K | train\n",
      "3 | deposit             | Sequential        | 16.5 K | train\n",
      "4 | task_heads          | ModuleDict        | 25.3 K | train\n",
      "5 | disabled_task_heads | ModuleDict        | 0      | train\n",
      "------------------------------------------------------------------\n",
      "124 K     Trainable params\n",
      "0         Non-trainable params\n",
      "124 K     Total params\n",
      "0.498     Total estimated model params size (MB)\n",
      "46        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 225/225 [00:03<00:00, 61.26it/s, v_num=0, train_final_loss_step=291.0, val_final_loss=236.0, train_final_loss_epoch=222.0]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 225/225 [00:03<00:00, 60.74it/s, v_num=0, train_final_loss_step=291.0, val_final_loss=236.0, train_final_loss_epoch=222.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:25:57.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: test ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:57.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:57.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:57.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:57.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (71725) into train_val (64552) and test (7173) using seed 24.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run run02 stage 3: best checkpoint -> /Users/liuchang/projects/foundation_model/artifacts/polymers_pretrain_finetune_runs/run02/pretrain_stage03_r2/checkpoints/r2-epoch=09-val_final_loss=235.7944.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:25:57.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (64552) into train (57379) and val (7173) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:57.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=57379, Validation=7173, Test=7173\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:57.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m666\u001b[0m - \u001b[1m--- Creating 'test' stage dataset ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:57.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m668\u001b[0m - \u001b[1mCreating test_dataset with 7173 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:57.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[test_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:57.509\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[test_dataset] Final x_formula shape: torch.Size([7173, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:57.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:57.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:57.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'r2' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:57.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[test_dataset] CompoundDataset initialization complete. Processed 3 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:57.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'test' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mLearnable task uncertainty (task_log_sigmas) is ENABLED.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mInitializing FlexibleMultiTaskModel...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mRegistered Task Heads:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m     name       type  enabled\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m       Rg REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m  density REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m       r2 REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[1mFlexibleMultiTaskModel Structure:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  FlexibleMultiTaskModel(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_log_sigmas): ParameterDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (Rg): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (density): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (r2): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (encoder): FoundationEncoder(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_heads): ModuleDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (Rg): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (density): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (r2): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (disabled_task_heads): ModuleDict()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mFlexibleMultiTaskModel initialization complete.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded Rg task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded density task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded r2 task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1406\u001b[0m - \u001b[1mSuccessfully loaded 3 optimizer states from dict format\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36mremove_tasks\u001b[0m:\u001b[36m514\u001b[0m - \u001b[1mRemoved tasks: Rg, density, r2\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1mAdded task 'density' (type=REGRESSION, enabled=True).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mActivated tasks during add_task: density\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mInitializing CompoundDataModule...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1m--- Loading Data ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'formula_desc' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'formula_desc'. Shape: (1083, 190)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mInitial loaded formula_df length: 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1mFormula_df length after initial dropna: 1083. This index is now the master reference.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'attributes' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'attributes'. Shape: (1083, 1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1mInitial loaded attributes_df length: 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--- Aligning DataFrames by formula_df index (master_index length: 1083) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mLength after aligning formula_df and attributes_df: 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m279\u001b[0m - \u001b[1mDataModule initialized with 1 task configurations.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m2025-10-31 09:25:58.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: TrainerFn.FITTING ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (1083) into train_val (974) and test (109) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (974) into train (865) and val (109) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=865, Validation=109, Test=109\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m462\u001b[0m - \u001b[1m--- Creating 'fit' stage datasets (train/val) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m464\u001b[0m - \u001b[1mCreating train_dataset with 865 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.156\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[train_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.156\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[train_dataset] Final x_formula shape: torch.Size([865, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[train_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m483\u001b[0m - \u001b[1mCreating val_dataset with 109 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[val_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[val_dataset] Final x_formula shape: torch.Size([109, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[val_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'TrainerFn.FITTING' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36mconfigure_optimizers\u001b[0m:\u001b[36m1037\u001b[0m - \u001b[1mAdded 1 task_log_sigmas parameters to the main optimizer.\u001b[0m\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:317: The lr scheduler dict contains the key(s) ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n",
      "\n",
      "  | Name                | Type              | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | task_log_sigmas     | ParameterDict     | 1      | train\n",
      "1 | encoder             | FoundationEncoder | 99.1 K | train\n",
      "2 | shared              | LinearBlock       | 82.6 K | train\n",
      "3 | deposit             | Sequential        | 16.5 K | train\n",
      "4 | task_heads          | ModuleDict        | 8.4 K  | train\n",
      "5 | disabled_task_heads | ModuleDict        | 0      | train\n",
      "------------------------------------------------------------------\n",
      "8.4 K     Trainable params\n",
      "99.1 K    Non-trainable params\n",
      "107 K     Total params\n",
      "0.430     Total estimated model params size (MB)\n",
      "26        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to ../artifacts/polymers_pretrain_finetune_runs/run02/pretrain_stage03_r2/prediction/predictions.parquet\n",
      "Saved metrics to ../artifacts/polymers_pretrain_finetune_runs/run02/pretrain_stage03_r2/prediction/metrics.json\n",
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 106.29it/s, v_num=0, train_final_loss_step=-0.347, val_final_loss=0.424, train_final_loss_epoch=-0.33]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 97.53it/s, v_num=0, train_final_loss_step=-0.347, val_final_loss=0.424, train_final_loss_epoch=-0.33] \n",
      "Run run02 finetune density: best checkpoint -> /Users/liuchang/projects/foundation_model/artifacts/polymers_pretrain_finetune_runs/run02/finetune_stage01_density/checkpoints/density-epoch=05-val_final_loss=-0.1406.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:25:58.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: test ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (1083) into train_val (974) and test (109) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (974) into train (865) and val (109) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=865, Validation=109, Test=109\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m666\u001b[0m - \u001b[1m--- Creating 'test' stage dataset ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m668\u001b[0m - \u001b[1mCreating test_dataset with 109 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[test_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[test_dataset] Final x_formula shape: torch.Size([109, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[test_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'test' complete ---\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to ../artifacts/polymers_pretrain_finetune_runs/run02/finetune_stage01_density/prediction/predictions.parquet\n",
      "Saved metrics to ../artifacts/polymers_pretrain_finetune_runs/run02/finetune_stage01_density/prediction/metrics.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:25:58.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mLearnable task uncertainty (task_log_sigmas) is ENABLED.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mInitializing FlexibleMultiTaskModel...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mRegistered Task Heads:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m     name       type  enabled\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m       Rg REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m  density REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m       r2 REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[1mFlexibleMultiTaskModel Structure:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  FlexibleMultiTaskModel(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_log_sigmas): ParameterDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (Rg): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (density): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (r2): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (encoder): FoundationEncoder(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_heads): ModuleDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (Rg): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (density): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (r2): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (disabled_task_heads): ModuleDict()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mFlexibleMultiTaskModel initialization complete.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded Rg task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded density task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded r2 task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1406\u001b[0m - \u001b[1mSuccessfully loaded 3 optimizer states from dict format\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36mremove_tasks\u001b[0m:\u001b[36m514\u001b[0m - \u001b[1mRemoved tasks: Rg, density, r2\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1mAdded task 'Rg' (type=REGRESSION, enabled=True).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mActivated tasks during add_task: Rg\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mInitializing CompoundDataModule...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1m--- Loading Data ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'formula_desc' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'formula_desc'. Shape: (1083, 190)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mInitial loaded formula_df length: 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1mFormula_df length after initial dropna: 1083. This index is now the master reference.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'attributes' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'attributes'. Shape: (1083, 1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1mInitial loaded attributes_df length: 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--- Aligning DataFrames by formula_df index (master_index length: 1083) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mLength after aligning formula_df and attributes_df: 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m279\u001b[0m - \u001b[1mDataModule initialized with 1 task configurations.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m2025-10-31 09:25:58.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: TrainerFn.FITTING ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (1083) into train_val (974) and test (109) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (974) into train (865) and val (109) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=865, Validation=109, Test=109\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m462\u001b[0m - \u001b[1m--- Creating 'fit' stage datasets (train/val) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m464\u001b[0m - \u001b[1mCreating train_dataset with 865 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[train_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[train_dataset] Final x_formula shape: torch.Size([865, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[train_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m483\u001b[0m - \u001b[1mCreating val_dataset with 109 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[val_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[val_dataset] Final x_formula shape: torch.Size([109, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[val_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'TrainerFn.FITTING' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:58.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36mconfigure_optimizers\u001b[0m:\u001b[36m1037\u001b[0m - \u001b[1mAdded 1 task_log_sigmas parameters to the main optimizer.\u001b[0m\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:317: The lr scheduler dict contains the key(s) ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n",
      "\n",
      "  | Name                | Type              | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | task_log_sigmas     | ParameterDict     | 1      | train\n",
      "1 | encoder             | FoundationEncoder | 99.1 K | train\n",
      "2 | shared              | LinearBlock       | 82.6 K | train\n",
      "3 | deposit             | Sequential        | 16.5 K | train\n",
      "4 | task_heads          | ModuleDict        | 8.4 K  | train\n",
      "5 | disabled_task_heads | ModuleDict        | 0      | train\n",
      "------------------------------------------------------------------\n",
      "8.4 K     Trainable params\n",
      "99.1 K    Non-trainable params\n",
      "107 K     Total params\n",
      "0.430     Total estimated model params size (MB)\n",
      "26        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 99.84it/s, v_num=0, train_final_loss_step=44.20, val_final_loss=51.80, train_final_loss_epoch=58.00] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 72.39it/s, v_num=0, train_final_loss_step=44.20, val_final_loss=51.80, train_final_loss_epoch=58.00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:25:59.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: test ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (1083) into train_val (974) and test (109) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (974) into train (865) and val (109) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=865, Validation=109, Test=109\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m666\u001b[0m - \u001b[1m--- Creating 'test' stage dataset ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m668\u001b[0m - \u001b[1mCreating test_dataset with 109 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[test_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[test_dataset] Final x_formula shape: torch.Size([109, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run run02 finetune Rg: best checkpoint -> /Users/liuchang/projects/foundation_model/artifacts/polymers_pretrain_finetune_runs/run02/finetune_stage02_rg/checkpoints/rg-epoch=09-val_final_loss=51.7675.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:25:59.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[test_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'test' complete ---\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to ../artifacts/polymers_pretrain_finetune_runs/run02/finetune_stage02_rg/prediction/predictions.parquet\n",
      "Saved metrics to ../artifacts/polymers_pretrain_finetune_runs/run02/finetune_stage02_rg/prediction/metrics.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:25:59.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mLearnable task uncertainty (task_log_sigmas) is ENABLED.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mInitializing FlexibleMultiTaskModel...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mRegistered Task Heads:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m     name       type  enabled\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m       Rg REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m  density REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m       r2 REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[1mFlexibleMultiTaskModel Structure:\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  FlexibleMultiTaskModel(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_log_sigmas): ParameterDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (Rg): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (density): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (r2): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (encoder): FoundationEncoder(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_heads): ModuleDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (Rg): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (density): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (r2): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (disabled_task_heads): ModuleDict()\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  )\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mFlexibleMultiTaskModel initialization complete.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded Rg task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded density task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded r2 task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1406\u001b[0m - \u001b[1mSuccessfully loaded 3 optimizer states from dict format\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36mremove_tasks\u001b[0m:\u001b[36m514\u001b[0m - \u001b[1mRemoved tasks: Rg, density, r2\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1mAdded task 'r2' (type=REGRESSION, enabled=True).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mActivated tasks during add_task: r2\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mInitializing CompoundDataModule...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1m--- Loading Data ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'formula_desc' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'formula_desc'. Shape: (1083, 190)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mInitial loaded formula_df length: 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1mFormula_df length after initial dropna: 1083. This index is now the master reference.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'attributes' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'attributes'. Shape: (1083, 1)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1mInitial loaded attributes_df length: 1083\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--- Aligning DataFrames by formula_df index (master_index length: 1083) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.652\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m231\u001b[0m - \u001b[33m\u001b[1mattributes_df contains NaN values after reindexing. This is expected if some properties are missing for certain samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.653\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m247\u001b[0m - \u001b[33m\u001b[1mMaster index (from formula_df) reduced from 1083 to 1078 after aligning with attributes_df. Some formula_df entries might not have corresponding attributes_df entries or vice-versa after NaN removal.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mLength after aligning formula_df and attributes_df: 1078\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m279\u001b[0m - \u001b[1mDataModule initialized with 1 task configurations.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m2025-10-31 09:25:59.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: TrainerFn.FITTING ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 1078\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (1078) into train_val (970) and test (108) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (970) into train (862) and val (108) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=862, Validation=108, Test=108\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m462\u001b[0m - \u001b[1m--- Creating 'fit' stage datasets (train/val) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m464\u001b[0m - \u001b[1mCreating train_dataset with 862 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[train_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[train_dataset] Final x_formula shape: torch.Size([862, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'r2' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[train_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m483\u001b[0m - \u001b[1mCreating val_dataset with 108 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[val_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[val_dataset] Final x_formula shape: torch.Size([108, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'r2' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[val_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'TrainerFn.FITTING' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:25:59.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36mconfigure_optimizers\u001b[0m:\u001b[36m1037\u001b[0m - \u001b[1mAdded 1 task_log_sigmas parameters to the main optimizer.\u001b[0m\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:317: The lr scheduler dict contains the key(s) ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n",
      "\n",
      "  | Name                | Type              | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | task_log_sigmas     | ParameterDict     | 1      | train\n",
      "1 | encoder             | FoundationEncoder | 99.1 K | train\n",
      "2 | shared              | LinearBlock       | 82.6 K | train\n",
      "3 | deposit             | Sequential        | 16.5 K | train\n",
      "4 | task_heads          | ModuleDict        | 8.4 K  | train\n",
      "5 | disabled_task_heads | ModuleDict        | 0      | train\n",
      "------------------------------------------------------------------\n",
      "8.4 K     Trainable params\n",
      "99.1 K    Non-trainable params\n",
      "107 K     Total params\n",
      "0.430     Total estimated model params size (MB)\n",
      "26        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 94.22it/s, v_num=0, train_final_loss_step=529.0, val_final_loss=152.0, train_final_loss_epoch=904.0]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4/4 [00:00<00:00, 72.39it/s, v_num=0, train_final_loss_step=529.0, val_final_loss=152.0, train_final_loss_epoch=904.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:26:00.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: test ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:26:00.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 1078\u001b[0m\n",
      "\u001b[32m2025-10-31 09:26:00.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 09:26:00.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 09:26:00.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (1078) into train_val (970) and test (108) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:26:00.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (970) into train (862) and val (108) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:26:00.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=862, Validation=108, Test=108\u001b[0m\n",
      "\u001b[32m2025-10-31 09:26:00.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m666\u001b[0m - \u001b[1m--- Creating 'test' stage dataset ---\u001b[0m\n",
      "\u001b[32m2025-10-31 09:26:00.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m668\u001b[0m - \u001b[1mCreating test_dataset with 108 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:26:00.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[test_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 09:26:00.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[test_dataset] Final x_formula shape: torch.Size([108, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 09:26:00.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'r2' (type: REGRESSION)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run run02 finetune r2: best checkpoint -> /Users/liuchang/projects/foundation_model/artifacts/polymers_pretrain_finetune_runs/run02/finetune_stage03_r2/checkpoints/r2-epoch=09-val_final_loss=151.9535.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 09:26:00.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[test_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 09:26:00.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'test' complete ---\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to ../artifacts/polymers_pretrain_finetune_runs/run02/finetune_stage03_r2/prediction/predictions.parquet\n",
      "Saved metrics to ../artifacts/polymers_pretrain_finetune_runs/run02/finetune_stage03_r2/prediction/metrics.json\n",
      "Completed all pretrain + finetune runs.\n"
     ]
    }
   ],
   "source": [
    "experiment_records: list[dict] = []\n",
    "\n",
    "for run_idx in range(1, NUM_PRETRAIN_RUNS + 1):\n",
    "    rng = random.Random(RANDOM_SEED_BASE + run_idx)\n",
    "    task_sequence = rng.sample(ALL_TASK_NAMES, k=len(ALL_TASK_NAMES))\n",
    "    run_label = f\"run{run_idx:02d}\"\n",
    "    print(f\"\"\"\n",
    "====================\n",
    "Starting {run_label}\n",
    "Task order: {task_sequence}\n",
    "====================\n",
    "\"\"\")\n",
    "\n",
    "    run_root = ARTIFACT_ROOT / run_label\n",
    "    run_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    previous_checkpoint: str | None = None\n",
    "    pretrain_stage_records: list[dict] = []\n",
    "\n",
    "    for stage_idx, task_name in enumerate(task_sequence, start=1):\n",
    "        stage_tasks = task_sequence[:stage_idx]\n",
    "        datamodule = build_pretrain_datamodule(stage_tasks)\n",
    "        task_configs = make_pretrain_task_configs(stage_tasks)\n",
    "\n",
    "        if previous_checkpoint is None:\n",
    "            model = FlexibleMultiTaskModel(\n",
    "                shared_block_dims=SHARED_BLOCK_DIMS,\n",
    "                task_configs=task_configs,\n",
    "                enable_learnable_loss_balancer=True,\n",
    "                shared_block_optimizer=OptimizerConfig(lr=1e-2),\n",
    "            )\n",
    "        else:\n",
    "            model = FlexibleMultiTaskModel.load_from_checkpoint(\n",
    "                checkpoint_path=previous_checkpoint,\n",
    "                strict=False,\n",
    "                enable_learnable_loss_balancer=True,\n",
    "            )\n",
    "            existing = set(model.task_heads.keys())\n",
    "            new_configs = [cfg for cfg in task_configs if cfg.name not in existing]\n",
    "            if new_configs:\n",
    "                model.add_task(*new_configs)\n",
    "\n",
    "        stage_dir = run_root / f\"pretrain_stage{stage_idx:02d}_{safe_slug(task_name)}\"\n",
    "        stage_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        checkpoint_cb = ModelCheckpoint(\n",
    "            dirpath=stage_dir / \"checkpoints\",\n",
    "            filename=f\"{safe_slug(task_name)}-{{epoch:02d}}-{{val_final_loss:.4f}}\",\n",
    "            monitor=\"val_final_loss\",\n",
    "            mode=\"min\",\n",
    "            save_top_k=1,\n",
    "        )\n",
    "        early_stopping = EarlyStopping(monitor=\"val_final_loss\", mode=\"min\", patience=10)\n",
    "        csv_logger = CSVLogger(save_dir=stage_dir / \"logs\", name=\"csv\")\n",
    "        tensorboard_logger = TensorBoardLogger(save_dir=stage_dir / \"logs\", name=\"tensorboard\")\n",
    "\n",
    "        trainer = Trainer(\n",
    "            max_epochs=PRETRAIN_MAX_EPOCHS,\n",
    "            accelerator=\"auto\",\n",
    "            devices=\"auto\",\n",
    "            callbacks=[checkpoint_cb, early_stopping],\n",
    "            logger=[csv_logger, tensorboard_logger],\n",
    "            log_every_n_steps=LOG_EVERY_N_STEPS,\n",
    "        )\n",
    "\n",
    "        trainer.fit(model, datamodule=datamodule)\n",
    "        best_model_path = checkpoint_cb.best_model_path\n",
    "        print(f\"Run {run_label} stage {stage_idx}: best checkpoint -> {best_model_path}\")\n",
    "\n",
    "        if best_model_path:\n",
    "            state = torch.load(best_model_path, map_location=\"cpu\", weights_only=True)\n",
    "            state_dict = state.get(\"state_dict\", state)\n",
    "            model.load_state_dict(state_dict)\n",
    "            previous_checkpoint = best_model_path\n",
    "        else:\n",
    "            print(\"Warning: no best checkpoint captured; using current weights.\")\n",
    "\n",
    "        prediction_dir = stage_dir / \"prediction\"\n",
    "        plot_test_predictions(\n",
    "            model=model,\n",
    "            datamodule=datamodule,\n",
    "            phase=\"pretrain\",\n",
    "            run_id=run_idx,\n",
    "            stage_num=stage_idx,\n",
    "            stage_tasks=stage_tasks,\n",
    "            new_task_name=task_name,\n",
    "            output_dir=prediction_dir,\n",
    "        )\n",
    "\n",
    "        pretrain_stage_records.append(\n",
    "            {\n",
    "                \"stage\": stage_idx,\n",
    "                \"task_name\": task_name,\n",
    "                \"task_sequence\": list(stage_tasks),\n",
    "                \"checkpoint\": best_model_path,\n",
    "                \"stage_dir\": stage_dir,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if previous_checkpoint is None:\n",
    "        raise RuntimeError(f\"Run {run_label} produced no pretrain checkpoint; cannot finetune.\")\n",
    "\n",
    "    finetune_records: list[dict] = []\n",
    "    for finetune_idx, task_name in enumerate(PI_TASK_NAMES, start=1):\n",
    "        finetune_model = FlexibleMultiTaskModel.load_from_checkpoint(\n",
    "            checkpoint_path=previous_checkpoint,\n",
    "            strict=False,\n",
    "            enable_learnable_loss_balancer=True,\n",
    "            freeze_shared_encoder=True,\n",
    "        )\n",
    "        active_tasks = list(finetune_model.task_heads.keys())\n",
    "        if active_tasks:\n",
    "            finetune_model.remove_tasks(*active_tasks)\n",
    "\n",
    "        task_config = make_pi_task_config(task_name)\n",
    "        finetune_model.add_task(task_config)\n",
    "\n",
    "        datamodule = build_pi_datamodule(task_name)\n",
    "\n",
    "        stage_dir = run_root / f\"finetune_stage{finetune_idx:02d}_{safe_slug(task_name)}\"\n",
    "        stage_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        checkpoint_cb = ModelCheckpoint(\n",
    "            dirpath=stage_dir / \"checkpoints\",\n",
    "            filename=f\"{safe_slug(task_name)}-{{epoch:02d}}-{{val_final_loss:.4f}}\",\n",
    "            monitor=\"val_final_loss\",\n",
    "            mode=\"min\",\n",
    "            save_top_k=1,\n",
    "        )\n",
    "        early_stopping = EarlyStopping(monitor=\"val_final_loss\", mode=\"min\", patience=10)\n",
    "        csv_logger = CSVLogger(save_dir=stage_dir / \"logs\", name=\"csv\")\n",
    "        tensorboard_logger = TensorBoardLogger(save_dir=stage_dir / \"logs\", name=\"tensorboard\")\n",
    "\n",
    "        trainer = Trainer(\n",
    "            max_epochs=FINETUNE_MAX_EPOCHS,\n",
    "            accelerator=\"auto\",\n",
    "            devices=\"auto\",\n",
    "            callbacks=[checkpoint_cb, early_stopping],\n",
    "            logger=[csv_logger, tensorboard_logger],\n",
    "            log_every_n_steps=LOG_EVERY_N_STEPS,\n",
    "        )\n",
    "\n",
    "        trainer.fit(finetune_model, datamodule=datamodule)\n",
    "        best_model_path = checkpoint_cb.best_model_path\n",
    "        print(f\"Run {run_label} finetune {task_name}: best checkpoint -> {best_model_path}\")\n",
    "\n",
    "        if best_model_path:\n",
    "            state = torch.load(best_model_path, map_location=\"cpu\", weights_only=True)\n",
    "            state_dict = state.get(\"state_dict\", state)\n",
    "            finetune_model.load_state_dict(state_dict)\n",
    "        else:\n",
    "            print(\"Warning: finetune stage missing checkpoint; using current weights.\")\n",
    "\n",
    "        prediction_dir = stage_dir / \"prediction\"\n",
    "        plot_test_predictions(\n",
    "            model=finetune_model,\n",
    "            datamodule=datamodule,\n",
    "            phase=\"finetune\",\n",
    "            run_id=run_idx,\n",
    "            stage_num=finetune_idx,\n",
    "            stage_tasks=[task_name],\n",
    "            new_task_name=task_name,\n",
    "            output_dir=prediction_dir,\n",
    "        )\n",
    "\n",
    "        finetune_records.append(\n",
    "            {\n",
    "                \"stage\": finetune_idx,\n",
    "                \"task_name\": task_name,\n",
    "                \"checkpoint\": best_model_path,\n",
    "                \"stage_dir\": stage_dir,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    experiment_records.append(\n",
    "        {\n",
    "            \"run\": run_label,\n",
    "            \"task_sequence\": task_sequence,\n",
    "            \"pretrain\": pretrain_stage_records,\n",
    "            \"pretrain_checkpoint\": previous_checkpoint,\n",
    "            \"finetune\": finetune_records,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"Completed all pretrain + finetune runs.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded 2 runs.\n",
      "run01 pretrain stages: 3 finetune stages: 3\n",
      "run02 pretrain stages: 3 finetune stages: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Recorded {len(experiment_records)} runs.\")\n",
    "for record in experiment_records:\n",
    "    print(record[\"run\"], \"pretrain stages:\", len(record[\"pretrain\"]), \"finetune stages:\", len(record[\"finetune\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f78c99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundation-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
