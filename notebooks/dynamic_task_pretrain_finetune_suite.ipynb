{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain & PI Finetuning Suite\n",
    "\n",
    "This notebook orchestrates 20 randomized incremental pretrain runs on non-PI polymers followed by PI-property finetuning with a frozen shared encoder. It combines the continual-task recipes from `dynamic_task_finetuning_demo.ipynb` and `dynamic_task_incremental_finetuning.ipynb`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "\n",
    "- **Descriptors**: `data/amorphous_polymer_FFDescriptor_20250730.parquet`\n",
    "- **Non-PI properties**: `data/amorphous_polymer_non_PI_properties_20250730.parquet`\n",
    "- **PI properties**: `data/amorphous_polymer_PI_properties_20250730.parquet`\n",
    "- Pretrain tasks: 15 properties (density through thermal_diffusivity) sampled in random order per run\n",
    "- PI finetune tasks: density, Rg, r2, self-diffusion, Cp, Cv, linear_expansion, refractive_index, tg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88d5efe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 11:53:56.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__init__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mLoguru logger initialized for foundation_model package.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger, TensorBoardLogger\n",
    "from loguru import logger as fm_logger\n",
    "\n",
    "from foundation_model.data.datamodule import CompoundDataModule\n",
    "from foundation_model.models.flexible_multi_task_model import FlexibleMultiTaskModel\n",
    "from foundation_model.models.model_config import OptimizerConfig, RegressionTaskConfig, TaskType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01ef6f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../data\")\n",
    "DESCRIPTOR_PATH = DATA_DIR / \"amorphous_polymer_FFDescriptor_20250730.parquet\"\n",
    "NON_PI_PATH = DATA_DIR / \"amorphous_polymer_non_PI_properties_20250730.parquet\"\n",
    "PI_PATH = DATA_DIR / \"amorphous_polymer_PI_properties_20250730.parquet\"\n",
    "SCALER_PATH = DATA_DIR / \"amorphous_polymer_properties_scaler_20250730.pkl.z\"\n",
    "\n",
    "USE_NORMALIZED_TARGETS = True  # If True, use normalized targets\n",
    "FINETUNE_FREEZE_SHARED = True  # If True, freeze shared encoder during finetuning\n",
    "QUIET_MODEL_LOGGING = True  # If True, reduce model logging output\n",
    "ENABLE_LEARNABLE_LOSS = False  # If True, enable learnable loss balancing\n",
    "KEEP_NORMALIZED_TARGETS = False  # If True, keep using normalized targets\n",
    "\n",
    "PRETRAIN_TASK_NAMES = [\n",
    "    \"density\",\n",
    "    \"Rg\",\n",
    "    \"r2\",\n",
    "    \"self-diffusion\",\n",
    "    \"Cp\",\n",
    "    \"Cv\",\n",
    "    \"bulk_modulus\",\n",
    "    \"volume_expansion\",\n",
    "    \"linear_expansion\",\n",
    "    \"static_dielectric_const\",\n",
    "    \"dielectric_const_dc\",\n",
    "    \"refractive_index\",\n",
    "    \"tg\",\n",
    "    \"thermal_conductivity\",\n",
    "    \"thermal_diffusivity\",\n",
    "]\n",
    "FINETUNE_TASK_NAMES = [\n",
    "    \"density\",\n",
    "    \"Rg\",\n",
    "    \"r2\",\n",
    "    \"self-diffusion\",\n",
    "    \"Cp\",\n",
    "    \"Cv\",\n",
    "    \"linear_expansion\",\n",
    "    \"refractive_index\",\n",
    "    \"tg\",\n",
    "]\n",
    "\n",
    "LOWER_CASE_PROPERTIES = sorted(set(PRETRAIN_TASK_NAMES) | set(FINETUNE_TASK_NAMES))\n",
    "\n",
    "def target_column(property_name: str) -> str:\n",
    "    return f\"{property_name}{' (normalized)' if USE_NORMALIZED_TARGETS else ''}\"\n",
    "\n",
    "TARGET_COLUMNS = {name: target_column(name) for name in LOWER_CASE_PROPERTIES}\n",
    "PRETRAIN_TARGET_COLUMNS = {name: TARGET_COLUMNS[name] for name in PRETRAIN_TASK_NAMES}\n",
    "FINETUNE_TARGET_COLUMNS = {name: TARGET_COLUMNS[name] for name in FINETUNE_TASK_NAMES}\n",
    "\n",
    "SHARED_BLOCK_DIMS = [190, 256, 128]\n",
    "HEAD_HIDDEN = 64\n",
    "ARTIFACT_ROOT = Path(\"../artifacts/polymers_pretrain_finetune_runs\")\n",
    "ARTIFACT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "NUM_PRETRAIN_RUNS = 10  # Number of pretraining runs with different random seeds\n",
    "PRETRAIN_MAX_EPOCHS = 200  # Max epochs for pretraining\n",
    "FINETUNE_MAX_EPOCHS = 200  # Max epochs for finetuning\n",
    "BATCH_SIZE = 256\n",
    "NUM_WORKERS = 0\n",
    "LOG_EVERY_N_STEPS = 20\n",
    "DATAMODULE_RANDOM_SEED = 42\n",
    "TASK_MASKING_RATIOS: float | dict[str, float] | None = None\n",
    "SWAP_TRAIN_VAL_SPLIT = 0.0\n",
    "VAL_SPLIT = 0.1\n",
    "TEST_SPLIT = 0.1\n",
    "TEST_ALL = False\n",
    "RANDOM_SEED_BASE = 1729\n",
    "\n",
    "PRETRAIN_SAMPLE = None  # Set to an int for smoke tests\n",
    "PI_SAMPLE = None  # Set to an int for smoke tests\n",
    "# PRETRAIN_SAMPLE = 2000  # Set to an int for smoke tests\n",
    "# PI_SAMPLE = 1000  # Set to an int for smoke tests\n",
    "\n",
    "PROPERTY_SCALERS: dict[str, Any] = {}\n",
    "\n",
    "if QUIET_MODEL_LOGGING:\n",
    "    fm_logger.disable(\"foundation_model\")\n",
    "else:\n",
    "    fm_logger.enable(\"foundation_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65832084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain feature matrix: (71725, 190)\n",
      "Pretrain target matrix: (71725, 15)\n",
      "PI feature matrix: (1083, 190)\n",
      "PI target matrix: (1083, 9)\n"
     ]
    }
   ],
   "source": [
    "descriptor_df = pd.read_parquet(DESCRIPTOR_PATH)\n",
    "non_pi_df = pd.read_parquet(NON_PI_PATH)\n",
    "pi_df = pd.read_parquet(PI_PATH)\n",
    "\n",
    "if USE_NORMALIZED_TARGETS:\n",
    "    if not SCALER_PATH.exists():\n",
    "        raise FileNotFoundError(f\"Missing scaler file: {SCALER_PATH}\")\n",
    "    PROPERTY_SCALERS = joblib.load(SCALER_PATH)\n",
    "    missing_scalers = [name for name in LOWER_CASE_PROPERTIES if name not in PROPERTY_SCALERS]\n",
    "    if missing_scalers:\n",
    "        raise KeyError(f\"Scaler missing entries for: {missing_scalers}\")\n",
    "else:\n",
    "    PROPERTY_SCALERS = {}\n",
    "\n",
    "missing_pretrain = [PRETRAIN_TARGET_COLUMNS[name] for name in PRETRAIN_TASK_NAMES if PRETRAIN_TARGET_COLUMNS[name] not in non_pi_df.columns]\n",
    "if missing_pretrain:\n",
    "    raise KeyError(f\"Non-PI table missing columns: {missing_pretrain}\")\n",
    "\n",
    "missing_finetune = [name for name in FINETUNE_TASK_NAMES if FINETUNE_TARGET_COLUMNS[name] not in pi_df.columns]\n",
    "if missing_finetune:\n",
    "    print(f\"Warning: PI table missing columns for tasks: {missing_finetune}. They will be skipped.\")\n",
    "available_finetune_tasks = [name for name in FINETUNE_TASK_NAMES if name not in missing_finetune]\n",
    "if not available_finetune_tasks:\n",
    "    raise ValueError(\"No PI finetune tasks remain after filtering missing columns.\")\n",
    "original_finetune_columns = FINETUNE_TARGET_COLUMNS\n",
    "FINETUNE_TASK_NAMES = available_finetune_tasks\n",
    "FINETUNE_TARGET_COLUMNS = {name: original_finetune_columns[name] for name in FINETUNE_TASK_NAMES}\n",
    "\n",
    "common_non_pi_index = descriptor_df.index.intersection(non_pi_df.index)\n",
    "pretrain_features = descriptor_df.loc[common_non_pi_index]\n",
    "pretrain_targets = non_pi_df.loc[common_non_pi_index, [PRETRAIN_TARGET_COLUMNS[name] for name in PRETRAIN_TASK_NAMES]]\n",
    "\n",
    "if PRETRAIN_SAMPLE is not None and PRETRAIN_SAMPLE < len(pretrain_features):\n",
    "    pretrain_features = pretrain_features.sample(n=PRETRAIN_SAMPLE, random_state=42)\n",
    "    pretrain_targets = pretrain_targets.loc[pretrain_features.index]\n",
    "\n",
    "common_pi_index = descriptor_df.index.intersection(pi_df.index)\n",
    "pi_features = descriptor_df.loc[common_pi_index]\n",
    "pi_targets = pi_df.loc[common_pi_index, [FINETUNE_TARGET_COLUMNS[name] for name in FINETUNE_TASK_NAMES]]\n",
    "\n",
    "if PI_SAMPLE is not None and PI_SAMPLE < len(pi_features):\n",
    "    pi_features = pi_features.sample(n=PI_SAMPLE, random_state=13)\n",
    "    pi_targets = pi_targets.loc[pi_features.index]\n",
    "\n",
    "print(f\"Pretrain feature matrix: {pretrain_features.shape}\")\n",
    "print(f\"Pretrain target matrix: {pretrain_targets.shape}\")\n",
    "print(f\"PI feature matrix: {pi_features.shape}\")\n",
    "print(f\"PI target matrix: {pi_targets.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0c5945",
   "metadata": {},
   "source": [
    "## Helper Utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f265d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pretrain_datamodule(\n",
    "    task_names: list[str],\n",
    "    *,\n",
    "    batch_size: int = BATCH_SIZE,\n",
    "    random_seed: int | None = DATAMODULE_RANDOM_SEED,\n",
    ") -> CompoundDataModule:\n",
    "    stage_targets = pretrain_targets.loc[:, [PRETRAIN_TARGET_COLUMNS[name] for name in task_names]]\n",
    "    return CompoundDataModule(\n",
    "        formula_desc_source=pretrain_features,\n",
    "        attributes_source=stage_targets,\n",
    "        task_configs=make_pretrain_task_configs(task_names),\n",
    "        task_masking_ratios=TASK_MASKING_RATIOS,\n",
    "        random_seed=random_seed,\n",
    "        val_split=VAL_SPLIT,\n",
    "        test_split=TEST_SPLIT,\n",
    "        test_all=TEST_ALL,\n",
    "        swap_train_val_split=SWAP_TRAIN_VAL_SPLIT,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n",
    "\n",
    "def build_finetune_datamodule(\n",
    "    task_name: str,\n",
    "    *,\n",
    "    batch_size: int = BATCH_SIZE,\n",
    "    random_seed: int | None = DATAMODULE_RANDOM_SEED,\n",
    ") -> CompoundDataModule:\n",
    "    target_frame = pi_targets.loc[:, [FINETUNE_TARGET_COLUMNS[task_name]]]\n",
    "    task_config = make_finetune_task_config(task_name)\n",
    "    return CompoundDataModule(\n",
    "        formula_desc_source=pi_features,\n",
    "        attributes_source=target_frame,\n",
    "        task_configs=[task_config],\n",
    "        task_masking_ratios=TASK_MASKING_RATIOS,\n",
    "        random_seed=random_seed,\n",
    "        val_split=VAL_SPLIT,\n",
    "        test_split=TEST_SPLIT,\n",
    "        test_all=TEST_ALL,\n",
    "        swap_train_val_split=SWAP_TRAIN_VAL_SPLIT,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c312b4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.serialization.add_safe_globals([RegressionTaskConfig, TaskType, OptimizerConfig])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ef7ae0",
   "metadata": {},
   "source": [
    "## Pretrain & Finetune Workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e909ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_records: list[dict] = []\n",
    "\n",
    "for run_idx in range(1, NUM_PRETRAIN_RUNS + 1):\n",
    "    rng = random.Random(RANDOM_SEED_BASE + run_idx)\n",
    "    task_sequence = rng.sample(PRETRAIN_TASK_NAMES, k=len(PRETRAIN_TASK_NAMES))\n",
    "    run_label = f\"run{run_idx:02d}\"\n",
    "    print(f\"\"\"\n",
    "====================\n",
    "Starting {run_label}\n",
    "Task order: {task_sequence}\n",
    "====================\"\"\"\n",
    ")\n",
    "\n",
    "    run_root = ARTIFACT_ROOT / run_label\n",
    "    run_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    previous_checkpoint: str | None = None\n",
    "    pretrain_stage_records: list[dict] = []\n",
    "    finetune_records: list[dict] = []\n",
    "\n",
    "    for stage_idx, task_name in enumerate(task_sequence, start=1):\n",
    "        stage_tasks = task_sequence[:stage_idx]\n",
    "        datamodule = build_pretrain_datamodule(stage_tasks, random_seed=RANDOM_SEED_BASE + run_idx)\n",
    "        task_configs = make_pretrain_task_configs(stage_tasks)\n",
    "\n",
    "        if previous_checkpoint is None:\n",
    "            model = FlexibleMultiTaskModel(\n",
    "                shared_block_dims=SHARED_BLOCK_DIMS,\n",
    "                task_configs=task_configs,\n",
    "                enable_learnable_loss_balancer=ENABLE_LEARNABLE_LOSS,\n",
    "                shared_block_optimizer=OptimizerConfig(lr=5e-2),\n",
    "            )\n",
    "        else:\n",
    "            model = FlexibleMultiTaskModel.load_from_checkpoint(\n",
    "                checkpoint_path=previous_checkpoint,\n",
    "                strict=False,\n",
    "                enable_learnable_loss_balancer=ENABLE_LEARNABLE_LOSS,\n",
    "            )\n",
    "            existing = set(model.task_heads.keys())\n",
    "            new_configs = [cfg for cfg in task_configs if cfg.name not in existing]\n",
    "            if new_configs:\n",
    "                model.add_task(*new_configs)\n",
    "\n",
    "        stage_dir = run_root / f\"pretrain_stage{stage_idx:02d}_{safe_slug(task_name)}\"\n",
    "        stage_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        checkpoint_cb = ModelCheckpoint(\n",
    "            dirpath=stage_dir / \"checkpoints\",\n",
    "            filename=f\"{safe_slug(task_name)}-{{epoch:02d}}-{{val_final_loss:.4f}}\",\n",
    "            monitor=\"val_final_loss\",\n",
    "            mode=\"min\",\n",
    "            save_top_k=1,\n",
    "        )\n",
    "        early_stopping = EarlyStopping(monitor=\"val_final_loss\", mode=\"min\", patience=10)\n",
    "        csv_logger = CSVLogger(save_dir=stage_dir / \"logs\", name=\"csv\")\n",
    "        tensorboard_logger = TensorBoardLogger(save_dir=stage_dir / \"logs\", name=\"tensorboard\")\n",
    "\n",
    "        trainer = Trainer(\n",
    "            max_epochs=PRETRAIN_MAX_EPOCHS,\n",
    "            accelerator=\"auto\",\n",
    "            devices=\"auto\",\n",
    "            callbacks=[checkpoint_cb, early_stopping],\n",
    "            logger=[csv_logger, tensorboard_logger],\n",
    "            log_every_n_steps=LOG_EVERY_N_STEPS,\n",
    "        )\n",
    "\n",
    "        trainer.fit(model, datamodule=datamodule)\n",
    "        best_model_path = checkpoint_cb.best_model_path\n",
    "        print(f\"Run {run_label} stage {stage_idx}: best checkpoint -> {best_model_path}\")\n",
    "\n",
    "        if best_model_path:\n",
    "            state = torch.load(best_model_path, map_location=\"cpu\", weights_only=True)\n",
    "            state_dict = state.get(\"state_dict\", state)\n",
    "            model.load_state_dict(state_dict)\n",
    "            previous_checkpoint = best_model_path\n",
    "        else:\n",
    "            print(\"Warning: no best checkpoint captured; using current weights.\")\n",
    "\n",
    "        prediction_dir = stage_dir / \"prediction\"\n",
    "        plot_test_predictions(\n",
    "            model=model,\n",
    "            datamodule=datamodule,\n",
    "            phase=\"pretrain\",\n",
    "            run_id=run_idx,\n",
    "            stage_num=stage_idx,\n",
    "            stage_tasks=stage_tasks,\n",
    "            new_task_name=task_name,\n",
    "            output_dir=prediction_dir,\n",
    "        )\n",
    "\n",
    "        stage_record = {\n",
    "            \"stage\": stage_idx,\n",
    "            \"task_name\": task_name,\n",
    "            \"task_sequence\": list(stage_tasks),\n",
    "            \"checkpoint\": previous_checkpoint,\n",
    "            \"stage_dir\": stage_dir,\n",
    "        }\n",
    "\n",
    "        stage_finetune_records: list[dict] = []\n",
    "        if previous_checkpoint is None:\n",
    "            print(\n",
    "                \"Warning: skipping finetune because no checkpoint is available for stage\",\n",
    "                stage_idx,\n",
    "            )\n",
    "        else:\n",
    "            for finetune_name in FINETUNE_TASK_NAMES:\n",
    "                finetune_model = FlexibleMultiTaskModel.load_from_checkpoint(\n",
    "                    checkpoint_path=previous_checkpoint,\n",
    "                    strict=False,\n",
    "                    enable_learnable_loss_balancer=ENABLE_LEARNABLE_LOSS,\n",
    "                    freeze_shared_encoder=FINETUNE_FREEZE_SHARED,\n",
    "                    shared_block_optimizer=OptimizerConfig(lr=5e-2),\n",
    "                )\n",
    "                active_tasks = list(finetune_model.task_heads.keys())\n",
    "                if active_tasks:\n",
    "                    finetune_model.remove_tasks(*active_tasks)\n",
    "\n",
    "                task_config = make_finetune_task_config(finetune_name)\n",
    "                finetune_model.add_task(task_config)\n",
    "\n",
    "                datamodule = build_finetune_datamodule(finetune_name, random_seed=RANDOM_SEED_BASE + run_idx)\n",
    "\n",
    "                finetune_root = stage_dir / \"finetune\"\n",
    "                finetune_stage_dir = finetune_root / safe_slug(finetune_name)\n",
    "                finetune_stage_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                checkpoint_cb = ModelCheckpoint(\n",
    "                    dirpath=finetune_stage_dir / \"checkpoints\",\n",
    "                    filename=f\"{safe_slug(finetune_name)}-{{epoch:02d}}-{{val_final_loss:.4f}}\",\n",
    "                    monitor=\"val_final_loss\",\n",
    "                    mode=\"min\",\n",
    "                    save_top_k=1,\n",
    "                )\n",
    "                early_stopping = EarlyStopping(\n",
    "                    monitor=\"val_final_loss\", mode=\"min\", patience=10\n",
    "                )\n",
    "                csv_logger = CSVLogger(save_dir=finetune_stage_dir / \"logs\", name=\"csv\")\n",
    "                tensorboard_logger = TensorBoardLogger(\n",
    "                    save_dir=finetune_stage_dir / \"logs\", name=\"tensorboard\"\n",
    "                )\n",
    "\n",
    "                trainer = Trainer(\n",
    "                    max_epochs=FINETUNE_MAX_EPOCHS,\n",
    "                    accelerator=\"auto\",\n",
    "                    devices=\"auto\",\n",
    "                    callbacks=[checkpoint_cb, early_stopping],\n",
    "                    logger=[csv_logger, tensorboard_logger],\n",
    "                    log_every_n_steps=LOG_EVERY_N_STEPS,\n",
    "                )\n",
    "\n",
    "                trainer.fit(finetune_model, datamodule=datamodule)\n",
    "                finetune_best_path = checkpoint_cb.best_model_path\n",
    "                print(\n",
    "                    f\"Run {run_label} stage {stage_idx} finetune {finetune_name}: \"\n",
    "                    f\"best checkpoint -> {finetune_best_path}\"\n",
    "                )\n",
    "\n",
    "                if finetune_best_path:\n",
    "                    state = torch.load(finetune_best_path, map_location=\"cpu\", weights_only=True)\n",
    "                    state_dict = state.get(\"state_dict\", state)\n",
    "                    finetune_model.load_state_dict(state_dict)\n",
    "                else:\n",
    "                    print(\"Warning: finetune stage missing checkpoint; using current weights.\")\n",
    "\n",
    "                prediction_dir = finetune_stage_dir / \"prediction\"\n",
    "                plot_test_predictions(\n",
    "                    model=finetune_model,\n",
    "                    datamodule=datamodule,\n",
    "                    phase=\"finetune\",\n",
    "                    run_id=run_idx,\n",
    "                    stage_num=stage_idx,\n",
    "                    stage_tasks=stage_tasks,\n",
    "                    new_task_name=finetune_name,\n",
    "                    output_dir=prediction_dir,\n",
    "                )\n",
    "\n",
    "                finetune_record = {\n",
    "                    \"stage\": stage_idx,\n",
    "                    \"task_name\": finetune_name,\n",
    "                    \"pretrain_task_sequence\": list(stage_tasks),\n",
    "                    \"checkpoint\": finetune_best_path,\n",
    "                    \"stage_dir\": finetune_stage_dir,\n",
    "                }\n",
    "                stage_finetune_records.append(finetune_record)\n",
    "                finetune_records.append(dict(finetune_record))\n",
    "\n",
    "        stage_record[\"finetune\"] = stage_finetune_records\n",
    "        pretrain_stage_records.append(stage_record)\n",
    "\n",
    "    if previous_checkpoint is None:\n",
    "        raise RuntimeError(f\"Run {run_label} produced no pretrain checkpoint; cannot finetune.\")\n",
    "\n",
    "    experiment_records.append(\n",
    "        {\n",
    "            \"run\": run_label,\n",
    "            \"task_sequence\": task_sequence,\n",
    "            \"pretrain\": pretrain_stage_records,\n",
    "            \"pretrain_checkpoint\": previous_checkpoint,\n",
    "            \"finetune\": finetune_records,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"Completed all pretrain + finetune runs.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad3bd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded 2 runs.\n",
      "run01 pretrain stages: 3 finetune stages: 3\n",
      "run02 pretrain stages: 3 finetune stages: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Recorded {len(experiment_records)} runs.\")\n",
    "for record in experiment_records:\n",
    "    stage_finetune_counts = [len(stage.get(\"finetune\", [])) for stage in record[\"pretrain\"]]\n",
    "    total_finetunes = sum(stage_finetune_counts)\n",
    "    print(\n",
    "        record[\"run\"],\n",
    "        \"pretrain stages:\",\n",
    "        len(record[\"pretrain\"]),\n",
    "        \"finetune stages:\",\n",
    "        total_finetunes,\n",
    "    )\n",
    "    for stage_record, count in zip(record[\"pretrain\"], stage_finetune_counts):\n",
    "        if count == 0:\n",
    "            continue\n",
    "        print(\n",
    "            \"  \",\n",
    "            f\"stage {stage_record['stage']:02d} ({stage_record['task_name']}):\",\n",
    "            f\"{count} finetune runs\",\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f78c99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundation-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}