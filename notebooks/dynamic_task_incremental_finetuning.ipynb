{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental Task Finetuning Demo\n",
    "\n",
    "This notebook incrementally adds regression tasks (density -> Cp -> Rg -> linear_expansion) using the flexible multi-task foundation model. Each stage reloads the previous checkpoint, adds a new task head, and continues training on the combined task set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "\n",
    "- **Descriptors**: `data/amorphous_polymer_FFDescriptor_20250730.parquet`\n",
    "- **Target properties**: `data/amorphous_polymer_non_PI_properties_20250730.parquet`\n",
    "- Sequential task order: density -> Cp -> Rg -> linear_expansion\n",
    "- The descriptor and property tables are aligned on their shared indices prior to splitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cba43da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 08:38:22.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__init__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mLoguru logger initialized for foundation_model package.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import math\n",
    "import json\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import CSVLogger, TensorBoardLogger\n",
    "\n",
    "from foundation_model.data.datamodule import CompoundDataModule\n",
    "from foundation_model.models.flexible_multi_task_model import FlexibleMultiTaskModel\n",
    "from foundation_model.models.model_config import RegressionTaskConfig, TaskType, OptimizerConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4cf7a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('../data')\n",
    "DESCRIPTOR_PATH = DATA_DIR / 'amorphous_polymer_FFDescriptor_20250730.parquet'\n",
    "PROPERTY_PATH = DATA_DIR / 'amorphous_polymer_non_PI_properties_20250730.parquet'\n",
    "\n",
    "USE_NORMALIZED_TARGETS = False\n",
    "TASK_SEQUENCE = ['density', 'Cp', 'Rg', 'linear_expansion']\n",
    "TARGET_COLUMNS = {\n",
    "    'density': f\"density{'(normalized)' if USE_NORMALIZED_TARGETS else ''}\",\n",
    "    'Cp': f\"Cp{'(normalized)' if USE_NORMALIZED_TARGETS else ''}\",\n",
    "    'Rg': f\"Rg{'(normalized)' if USE_NORMALIZED_TARGETS else ''}\",\n",
    "    'linear_expansion': f\"linear_expansion{'(normalized)' if USE_NORMALIZED_TARGETS else ''}\",\n",
    "}\n",
    "\n",
    "SHARED_BLOCK_DIMS = [190, 256, 128]\n",
    "HEAD_HIDDEN = 64\n",
    "ARTIFACT_ROOT = Path('../artifacts/polymers_incremental_tasks')\n",
    "ARTIFACT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_SAMPLE = None  # set to an int for faster smoke runs\n",
    "BATCH_SIZE = 256\n",
    "NUM_WORKERS = 0\n",
    "MAX_EPOCHS = 20\n",
    "LOG_EVERY_N_STEPS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a9e556a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix: (71725, 190)\n",
      "Target matrix: (71725, 4)\n",
      "First targets: ['density', 'Cp', 'Rg', 'linear_expansion']\n"
     ]
    }
   ],
   "source": [
    "descriptor_df = pd.read_parquet(DESCRIPTOR_PATH)\n",
    "property_df = pd.read_parquet(PROPERTY_PATH)\n",
    "\n",
    "missing = [col for col in TARGET_COLUMNS.values() if col not in property_df.columns]\n",
    "if missing:\n",
    "    raise KeyError(f'Missing target columns in property table: {missing}')\n",
    "\n",
    "common_index = descriptor_df.index.intersection(property_df.index)\n",
    "feature_frame = descriptor_df.loc[common_index]\n",
    "target_frame = property_df.loc[common_index, [TARGET_COLUMNS[name] for name in TASK_SEQUENCE]]\n",
    "\n",
    "if TRAIN_SAMPLE is not None and TRAIN_SAMPLE < len(feature_frame):\n",
    "    feature_frame = feature_frame.sample(n=TRAIN_SAMPLE, random_state=42)\n",
    "    target_frame = target_frame.loc[feature_frame.index]\n",
    "\n",
    "print(f'Feature matrix: {feature_frame.shape}')\n",
    "print(f'Target matrix: {target_frame.shape}')\n",
    "print(f'First targets: {list(target_frame.columns)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14a759e",
   "metadata": {},
   "source": [
    "## Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38b574a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_regression_task(name: str, column: str) -> RegressionTaskConfig:\n",
    "    return RegressionTaskConfig(\n",
    "        name=name,\n",
    "        data_column=column,\n",
    "        dims=[SHARED_BLOCK_DIMS[-1], HEAD_HIDDEN, 1],\n",
    "        norm=True,\n",
    "        residual=False,\n",
    "    )\n",
    "\n",
    "def make_task_configs(task_names: list[str]) -> list[RegressionTaskConfig]:\n",
    "    return [build_regression_task(task_name, TARGET_COLUMNS[task_name]) for task_name in task_names]\n",
    "\n",
    "def build_datamodule(task_configs: list[RegressionTaskConfig], *, batch_size: int = BATCH_SIZE) -> CompoundDataModule:\n",
    "    stage_targets = target_frame.loc[:, [cfg.data_column for cfg in task_configs]]\n",
    "    return CompoundDataModule(\n",
    "        formula_desc_source=feature_frame,\n",
    "        attributes_source=stage_targets,\n",
    "        task_configs=task_configs,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5156dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_predictions(\n",
    "    model: FlexibleMultiTaskModel,\n",
    "    datamodule: CompoundDataModule,\n",
    "    *,\n",
    "    stage_num: int,\n",
    "    stage_tasks: list[str],\n",
    "    new_task_name: str,\n",
    "    prediction_dir: Path | str | None = None,\n",
    ") -> None:\n",
    "    # Render predicted vs. actual scatter plots and persist evaluation artifacts.\n",
    "    if prediction_dir is None:\n",
    "        prediction_dir = ARTIFACT_ROOT / f'Stage{stage_num}_{new_task_name}' / 'prediction'\n",
    "    prediction_dir = Path(prediction_dir)\n",
    "    prediction_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    metrics_path = prediction_dir / 'metrics.json'\n",
    "    predictions_path = prediction_dir / 'predictions.parquet'\n",
    "    task_order_path = prediction_dir / 'tasks.txt'\n",
    "    task_order_path.write_text(' -> '.join(stage_tasks) + '', encoding='utf-8')\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        device = 'mps'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "\n",
    "    datamodule.setup(stage='test')\n",
    "    test_loader = datamodule.test_dataloader()\n",
    "    if test_loader is None:\n",
    "        raise RuntimeError(f'Stage {stage_num} datamodule does not define a test_dataloader().')\n",
    "\n",
    "    original_device = next(model.parameters()).device\n",
    "    was_training = model.training\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    aggregated: dict[str, dict[str, list[torch.Tensor]]] = {}\n",
    "    prediction_rows: list[dict[str, float | str | int]] = []\n",
    "    per_task_counts: dict[str, int] = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            x, y_dict, mask_dict, t_sequences = batch\n",
    "            x = x.to(device)\n",
    "            preds = model(x, t_sequences)\n",
    "\n",
    "            for name, pred_tensor in preds.items():\n",
    "                if name not in y_dict:\n",
    "                    continue\n",
    "\n",
    "                target_tensor = y_dict[name]\n",
    "                mask_tensor = mask_dict.get(name)\n",
    "\n",
    "                if isinstance(target_tensor, list):\n",
    "                    target_flat = torch.cat([t.detach().cpu().reshape(-1) for t in target_tensor])\n",
    "                else:\n",
    "                    target_flat = target_tensor.detach().cpu().reshape(-1)\n",
    "\n",
    "                pred_flat = pred_tensor.detach().cpu().reshape(-1)\n",
    "\n",
    "                if mask_tensor is not None:\n",
    "                    if isinstance(mask_tensor, list):\n",
    "                        mask_flat = torch.cat([m.detach().cpu().reshape(-1) for m in mask_tensor])\n",
    "                    else:\n",
    "                        mask_flat = mask_tensor.detach().cpu().reshape(-1)\n",
    "                    mask_flat = mask_flat.bool()\n",
    "                    target_flat = target_flat[mask_flat]\n",
    "                    pred_flat = pred_flat[mask_flat]\n",
    "\n",
    "                if target_flat.numel() == 0:\n",
    "                    continue\n",
    "\n",
    "                entry = aggregated.setdefault(name, {'preds': [], 'targets': []})\n",
    "                entry['preds'].append(pred_flat)\n",
    "                entry['targets'].append(target_flat)\n",
    "\n",
    "                start_idx = per_task_counts.get(name, 0)\n",
    "                for offset, (actual_val, pred_val) in enumerate(zip(target_flat.tolist(), pred_flat.tolist())):\n",
    "                    prediction_rows.append(\n",
    "                        {\n",
    "                            'stage': stage_num,\n",
    "                            'task': name,\n",
    "                            'sample_index': start_idx + offset,\n",
    "                            'actual': actual_val,\n",
    "                            'predicted': pred_val,\n",
    "                        }\n",
    "                    )\n",
    "                per_task_counts[name] = start_idx + target_flat.numel()\n",
    "\n",
    "    if not aggregated:\n",
    "        print(f'No test predictions available for Stage {stage_num}.')\n",
    "        model.to(original_device)\n",
    "        if was_training:\n",
    "            model.train()\n",
    "        return\n",
    "\n",
    "    ordered_items = [(name, aggregated[name]) for name in stage_tasks if name in aggregated]\n",
    "\n",
    "    metrics: dict[str, dict[str, float | int | None]] = {}\n",
    "    num_tasks = len(ordered_items)\n",
    "    cols = 2 if num_tasks > 1 else 1\n",
    "    rows = math.ceil(num_tasks / cols)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4.5, rows * 4.5))\n",
    "    if hasattr(axes, 'flat'):\n",
    "        axes_list = list(axes.flat)\n",
    "    else:\n",
    "        axes_list = [axes]\n",
    "\n",
    "    for ax, (name, data) in zip(axes_list, ordered_items):\n",
    "        preds = torch.cat(data['preds'])\n",
    "        targets = torch.cat(data['targets'])\n",
    "        diff = preds - targets\n",
    "        mae = torch.mean(torch.abs(diff)).item()\n",
    "        mse = torch.mean(diff ** 2).item()\n",
    "        rmse = torch.sqrt(torch.mean(diff ** 2)).item()\n",
    "        ss_tot = torch.sum((targets - targets.mean()) ** 2).item()\n",
    "        ss_res = torch.sum(diff ** 2).item()\n",
    "        r2 = 1.0 - ss_res / ss_tot if ss_tot > 0 else None\n",
    "\n",
    "        metrics[name] = {\n",
    "            'samples': int(targets.numel()),\n",
    "            'mae': mae,\n",
    "            'mse': mse,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2,\n",
    "        }\n",
    "\n",
    "        preds_np = preds.numpy()\n",
    "        targets_np = targets.numpy()\n",
    "        lo = float(min(preds_np.min(), targets_np.min()))\n",
    "        hi = float(max(preds_np.max(), targets_np.max()))\n",
    "        buffer = 0.05 * (hi - lo) if hi > lo else 0.1\n",
    "        lo -= buffer\n",
    "        hi += buffer\n",
    "\n",
    "        ax.scatter(targets_np, preds_np, s=12, alpha=0.6, edgecolors='none')\n",
    "        ax.plot([lo, hi], [lo, hi], '--', color='tab:red', linewidth=1)\n",
    "        if r2 is not None:\n",
    "            annotation = rf\"MAE: {mae:.3f} $R^2$: {r2:.3f}\"\n",
    "        else:\n",
    "            annotation = f\"MAE: {mae:.3f}\"\n",
    "        ax.text(\n",
    "            0.05,\n",
    "            0.95,\n",
    "            annotation,\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=10,\n",
    "            verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.6),\n",
    "        )\n",
    "        ax.set_xlim(lo, hi)\n",
    "        ax.set_ylim(lo, hi)\n",
    "        ax.set_xlabel('Actual')\n",
    "        ax.set_ylabel('Predicted')\n",
    "        ax.set_title(f'Stage {stage_num}: {name}')\n",
    "        ax.grid(alpha=0.2)\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "    for ax in axes_list[len(ordered_items):]:\n",
    "        ax.axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(prediction_dir / f'Stage{stage_num}_overview.png', dpi=180)\n",
    "    plt.close(fig)\n",
    "\n",
    "    for name, data in ordered_items:\n",
    "        preds = torch.cat(data['preds'])\n",
    "        targets = torch.cat(data['targets'])\n",
    "        preds_np = preds.numpy()\n",
    "        targets_np = targets.numpy()\n",
    "        lo = float(min(preds_np.min(), targets_np.min()))\n",
    "        hi = float(max(preds_np.max(), targets_np.max()))\n",
    "        buffer = 0.05 * (hi - lo) if hi > lo else 0.1\n",
    "        lo -= buffer\n",
    "        hi += buffer\n",
    "\n",
    "        fig_single, ax_single = plt.subplots(figsize=(5, 5))\n",
    "        ax_single.scatter(targets_np, preds_np, s=12, alpha=0.6, edgecolors='none')\n",
    "        ax_single.plot([lo, hi], [lo, hi], '--', color='tab:red', linewidth=1)\n",
    "        ax_single.set_xlim(lo, hi)\n",
    "        ax_single.set_ylim(lo, hi)\n",
    "        ax_single.set_xlabel('Actual')\n",
    "        ax_single.set_ylabel('Predicted')\n",
    "        ax_single.set_title(f'Stage {stage_num}: {name}')\n",
    "        ax_single.grid(alpha=0.2)\n",
    "        ax_single.set_aspect('equal', adjustable='box')\n",
    "        fig_single.tight_layout()\n",
    "        safe_name = re.sub(r'[^a-z0-9]+', '_', name.lower()).strip('_') or 'task'\n",
    "        fig_single.savefig(prediction_dir / f'{safe_name}_pred.png', dpi=180)\n",
    "        plt.close(fig_single)\n",
    "\n",
    "    metrics_payload = {\n",
    "        'stage': stage_num,\n",
    "        'task_sequence': list(stage_tasks),\n",
    "        'metrics': metrics,\n",
    "    }\n",
    "\n",
    "    if prediction_rows:\n",
    "        pd.DataFrame(prediction_rows).to_parquet(predictions_path, index=False)\n",
    "        print(f'Saved predictions to {predictions_path}')\n",
    "\n",
    "    with open(metrics_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metrics_payload, f, indent=2)\n",
    "    print(f'Saved metrics to {metrics_path}')\n",
    "\n",
    "    model.to(original_device)\n",
    "    if was_training:\n",
    "        model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e697bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.serialization.add_safe_globals([RegressionTaskConfig, TaskType, OptimizerConfig])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb52705a",
   "metadata": {},
   "source": [
    "## Incremental Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daf44f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 08:38:30.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mInitializing CompoundDataModule...\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1m--- Loading Data ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'formula_desc' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'formula_desc'. Shape: (71725, 190)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mInitial loaded formula_df length: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1mFormula_df length after initial dropna: 71725. This index is now the master reference.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'attributes' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'attributes'. Shape: (71725, 1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1mInitial loaded attributes_df length: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--- Aligning DataFrames by formula_df index (master_index length: 71725) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mLength after aligning formula_df and attributes_df: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m279\u001b[0m - \u001b[1mDataModule initialized with 1 task configurations.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mLearnable task uncertainty (task_log_sigmas) is ENABLED.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mInitializing FlexibleMultiTaskModel...\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mRegistered Task Heads:\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m     name       type  enabled\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m  density REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[1mFlexibleMultiTaskModel Structure:\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  FlexibleMultiTaskModel(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_log_sigmas): ParameterDict(  (density): Parameter containing: [torch.FloatTensor of size ])\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (encoder): FoundationEncoder(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_heads): ModuleDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (density): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (disabled_task_heads): ModuleDict()\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mFlexibleMultiTaskModel initialization complete.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m2025-10-31 08:38:30.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: TrainerFn.FITTING ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (71725) into train_val (64552) and test (7173) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (64552) into train (57379) and val (7173) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=57379, Validation=7173, Test=7173\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m462\u001b[0m - \u001b[1m--- Creating 'fit' stage datasets (train/val) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m464\u001b[0m - \u001b[1mCreating train_dataset with 57379 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[train_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[train_dataset] Final x_formula shape: torch.Size([57379, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Stage 1 (density) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 08:38:30.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[train_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m483\u001b[0m - \u001b[1mCreating val_dataset with 7173 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[val_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[val_dataset] Final x_formula shape: torch.Size([7173, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[val_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'TrainerFn.FITTING' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:38:30.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36mconfigure_optimizers\u001b[0m:\u001b[36m1037\u001b[0m - \u001b[1mAdded 1 task_log_sigmas parameters to the main optimizer.\u001b[0m\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:317: The lr scheduler dict contains the key(s) ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n",
      "\n",
      "  | Name                | Type              | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | task_log_sigmas     | ParameterDict     | 1      | train\n",
      "1 | encoder             | FoundationEncoder | 99.1 K | train\n",
      "2 | shared              | LinearBlock       | 82.6 K | train\n",
      "3 | deposit             | Sequential        | 16.5 K | train\n",
      "4 | task_heads          | ModuleDict        | 8.4 K  | train\n",
      "5 | disabled_task_heads | ModuleDict        | 0      | train\n",
      "------------------------------------------------------------------\n",
      "107 K     Trainable params\n",
      "0         Non-trainable params\n",
      "107 K     Total params\n",
      "0.430     Total estimated model params size (MB)\n",
      "26        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 225/225 [00:01<00:00, 118.15it/s, v_num=0, train_final_loss_step=-2.26, val_final_loss=-2.51, train_final_loss_epoch=-2.47] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 225/225 [00:01<00:00, 117.03it/s, v_num=0, train_final_loss_step=-2.26, val_final_loss=-2.51, train_final_loss_epoch=-2.47]\n",
      "Best checkpoint: /Users/liuchang/projects/foundation_model/artifacts/polymers_incremental_tasks/Stage1_density/checkpoints/density-epoch=19-val_final_loss=-2.5144.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 08:39:09.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: test ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:09.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:09.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:09.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:09.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (71725) into train_val (64552) and test (7173) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:09.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (64552) into train (57379) and val (7173) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:09.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=57379, Validation=7173, Test=7173\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:09.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m666\u001b[0m - \u001b[1m--- Creating 'test' stage dataset ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:09.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m668\u001b[0m - \u001b[1mCreating test_dataset with 7173 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:09.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[test_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:09.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[test_dataset] Final x_formula shape: torch.Size([7173, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:09.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:09.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[test_dataset] CompoundDataset initialization complete. Processed 1 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:09.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'test' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mInitializing CompoundDataModule...\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1m--- Loading Data ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'formula_desc' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'formula_desc'. Shape: (71725, 190)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mInitial loaded formula_df length: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1mFormula_df length after initial dropna: 71725. This index is now the master reference.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'attributes' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'attributes'. Shape: (71725, 2)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1mInitial loaded attributes_df length: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--- Aligning DataFrames by formula_df index (master_index length: 71725) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.213\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m231\u001b[0m - \u001b[33m\u001b[1mattributes_df contains NaN values after reindexing. This is expected if some properties are missing for certain samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mLength after aligning formula_df and attributes_df: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m279\u001b[0m - \u001b[1mDataModule initialized with 2 task configurations.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mLearnable task uncertainty (task_log_sigmas) is ENABLED.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mInitializing FlexibleMultiTaskModel...\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mRegistered Task Heads:\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m     name       type  enabled\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m  density REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[1mFlexibleMultiTaskModel Structure:\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  FlexibleMultiTaskModel(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_log_sigmas): ParameterDict(  (density): Parameter containing: [torch.FloatTensor of size ])\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (encoder): FoundationEncoder(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_heads): ModuleDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (density): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (disabled_task_heads): ModuleDict()\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mFlexibleMultiTaskModel initialization complete.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1384\u001b[0m - \u001b[1mLoaded shared_encoder optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded density task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1406\u001b[0m - \u001b[1mSuccessfully loaded 2 optimizer states from dict format\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1mAdded task 'Cp' (type=REGRESSION, enabled=True).\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mActivated tasks during add_task: Cp\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m2025-10-31 08:39:10.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: TrainerFn.FITTING ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (71725) into train_val (64552) and test (7173) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (64552) into train (57379) and val (7173) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=57379, Validation=7173, Test=7173\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m462\u001b[0m - \u001b[1m--- Creating 'fit' stage datasets (train/val) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m464\u001b[0m - \u001b[1mCreating train_dataset with 57379 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[train_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[train_dataset] Final x_formula shape: torch.Size([57379, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to ../artifacts/polymers_incremental_tasks/Stage1_density/prediction/predictions.parquet\n",
      "Saved metrics to ../artifacts/polymers_incremental_tasks/Stage1_density/prediction/metrics.json\n",
      "=== Stage 2 (Cp) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 08:39:10.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'Cp' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[train_dataset] CompoundDataset initialization complete. Processed 2 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m483\u001b[0m - \u001b[1mCreating val_dataset with 7173 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[val_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[val_dataset] Final x_formula shape: torch.Size([7173, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'Cp' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[val_dataset] CompoundDataset initialization complete. Processed 2 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'TrainerFn.FITTING' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:39:10.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36mconfigure_optimizers\u001b[0m:\u001b[36m1037\u001b[0m - \u001b[1mAdded 2 task_log_sigmas parameters to the main optimizer.\u001b[0m\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:317: The lr scheduler dict contains the key(s) ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n",
      "\n",
      "  | Name                | Type              | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | task_log_sigmas     | ParameterDict     | 2      | train\n",
      "1 | encoder             | FoundationEncoder | 99.1 K | train\n",
      "2 | shared              | LinearBlock       | 82.6 K | train\n",
      "3 | deposit             | Sequential        | 16.5 K | train\n",
      "4 | task_heads          | ModuleDict        | 16.9 K | train\n",
      "5 | disabled_task_heads | ModuleDict        | 0      | train\n",
      "------------------------------------------------------------------\n",
      "115 K     Trainable params\n",
      "0         Non-trainable params\n",
      "115 K     Total params\n",
      "0.464     Total estimated model params size (MB)\n",
      "36        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 225/225 [00:03<00:00, 74.47it/s, v_num=0, train_final_loss_step=3.62e+5, val_final_loss=3.89e+5, train_final_loss_epoch=3.94e+5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 225/225 [00:03<00:00, 73.88it/s, v_num=0, train_final_loss_step=3.62e+5, val_final_loss=3.89e+5, train_final_loss_epoch=3.94e+5]\n",
      "Best checkpoint: /Users/liuchang/projects/foundation_model/artifacts/polymers_incremental_tasks/Stage2_Cp/checkpoints/Cp-epoch=19-val_final_loss=388704.4688.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 08:40:10.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: test ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (71725) into train_val (64552) and test (7173) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (64552) into train (57379) and val (7173) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=57379, Validation=7173, Test=7173\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m666\u001b[0m - \u001b[1m--- Creating 'test' stage dataset ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m668\u001b[0m - \u001b[1mCreating test_dataset with 7173 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[test_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[test_dataset] Final x_formula shape: torch.Size([7173, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'Cp' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[test_dataset] CompoundDataset initialization complete. Processed 2 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'test' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mInitializing CompoundDataModule...\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1m--- Loading Data ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'formula_desc' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'formula_desc'. Shape: (71725, 190)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mInitial loaded formula_df length: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1mFormula_df length after initial dropna: 71725. This index is now the master reference.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'attributes' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'attributes'. Shape: (71725, 3)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1mInitial loaded attributes_df length: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--- Aligning DataFrames by formula_df index (master_index length: 71725) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.951\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m231\u001b[0m - \u001b[33m\u001b[1mattributes_df contains NaN values after reindexing. This is expected if some properties are missing for certain samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mLength after aligning formula_df and attributes_df: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m279\u001b[0m - \u001b[1mDataModule initialized with 3 task configurations.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mLearnable task uncertainty (task_log_sigmas) is ENABLED.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mInitializing FlexibleMultiTaskModel...\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mRegistered Task Heads:\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m     name       type  enabled\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m  density REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m       Cp REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[1mFlexibleMultiTaskModel Structure:\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  FlexibleMultiTaskModel(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_log_sigmas): ParameterDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (density): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (Cp): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (encoder): FoundationEncoder(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:10.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_heads): ModuleDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (density): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (Cp): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (disabled_task_heads): ModuleDict()\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mFlexibleMultiTaskModel initialization complete.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1384\u001b[0m - \u001b[1mLoaded shared_encoder optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded density task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded Cp task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1406\u001b[0m - \u001b[1mSuccessfully loaded 3 optimizer states from dict format\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1mAdded task 'Rg' (type=REGRESSION, enabled=True).\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mActivated tasks during add_task: Rg\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m2025-10-31 08:40:11.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: TrainerFn.FITTING ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (71725) into train_val (64552) and test (7173) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (64552) into train (57379) and val (7173) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=57379, Validation=7173, Test=7173\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m462\u001b[0m - \u001b[1m--- Creating 'fit' stage datasets (train/val) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m464\u001b[0m - \u001b[1mCreating train_dataset with 57379 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[train_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[train_dataset] Final x_formula shape: torch.Size([57379, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to ../artifacts/polymers_incremental_tasks/Stage2_Cp/prediction/predictions.parquet\n",
      "Saved metrics to ../artifacts/polymers_incremental_tasks/Stage2_Cp/prediction/metrics.json\n",
      "=== Stage 3 (Rg) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 08:40:11.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'Cp' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[train_dataset] CompoundDataset initialization complete. Processed 3 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m483\u001b[0m - \u001b[1mCreating val_dataset with 7173 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[val_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[val_dataset] Final x_formula shape: torch.Size([7173, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'Cp' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.377\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[val_dataset] CompoundDataset initialization complete. Processed 3 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'TrainerFn.FITTING' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:40:11.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36mconfigure_optimizers\u001b[0m:\u001b[36m1037\u001b[0m - \u001b[1mAdded 3 task_log_sigmas parameters to the main optimizer.\u001b[0m\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:317: The lr scheduler dict contains the key(s) ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n",
      "\n",
      "  | Name                | Type              | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | task_log_sigmas     | ParameterDict     | 3      | train\n",
      "1 | encoder             | FoundationEncoder | 99.1 K | train\n",
      "2 | shared              | LinearBlock       | 82.6 K | train\n",
      "3 | deposit             | Sequential        | 16.5 K | train\n",
      "4 | task_heads          | ModuleDict        | 25.3 K | train\n",
      "5 | disabled_task_heads | ModuleDict        | 0      | train\n",
      "------------------------------------------------------------------\n",
      "124 K     Trainable params\n",
      "0         Non-trainable params\n",
      "124 K     Total params\n",
      "0.498     Total estimated model params size (MB)\n",
      "46        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 225/225 [00:03<00:00, 58.47it/s, v_num=0, train_final_loss_step=1.52e+4, val_final_loss=1.62e+4, train_final_loss_epoch=1.65e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 225/225 [00:03<00:00, 58.01it/s, v_num=0, train_final_loss_step=1.52e+4, val_final_loss=1.62e+4, train_final_loss_epoch=1.65e+4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 08:41:29.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: test ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (71725) into train_val (64552) and test (7173) using seed 24.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best checkpoint: /Users/liuchang/projects/foundation_model/artifacts/polymers_incremental_tasks/Stage3_Rg/checkpoints/Rg-epoch=19-val_final_loss=16172.6553.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 08:41:29.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (64552) into train (57379) and val (7173) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=57379, Validation=7173, Test=7173\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m666\u001b[0m - \u001b[1m--- Creating 'test' stage dataset ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m668\u001b[0m - \u001b[1mCreating test_dataset with 7173 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[test_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[test_dataset] Final x_formula shape: torch.Size([7173, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'Cp' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[test_dataset] CompoundDataset initialization complete. Processed 3 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'test' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mInitializing CompoundDataModule...\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1m--- Loading Data ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'formula_desc' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'formula_desc'. Shape: (71725, 190)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m197\u001b[0m - \u001b[1mInitial loaded formula_df length: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.552\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m204\u001b[0m - \u001b[1mFormula_df length after initial dropna: 71725. This index is now the master reference.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.552\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mUsing provided pd.DataFrame for 'attributes' data.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_load_data\u001b[0m:\u001b[36m439\u001b[0m - \u001b[1mSuccessfully loaded 'attributes'. Shape: (71725, 4)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m218\u001b[0m - \u001b[1mInitial loaded attributes_df length: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m221\u001b[0m - \u001b[1m--- Aligning DataFrames by formula_df index (master_index length: 71725) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.555\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m231\u001b[0m - \u001b[33m\u001b[1mattributes_df contains NaN values after reindexing. This is expected if some properties are missing for certain samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mLength after aligning formula_df and attributes_df: 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m279\u001b[0m - \u001b[1mDataModule initialized with 4 task configurations.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mLearnable task uncertainty (task_log_sigmas) is ENABLED.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m162\u001b[0m - \u001b[1mInitializing FlexibleMultiTaskModel...\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mRegistered Task Heads:\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m     name       type  enabled\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m  density REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m       Cp REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m170\u001b[0m - \u001b[1m       Rg REGRESSION     True\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m174\u001b[0m - \u001b[1mFlexibleMultiTaskModel Structure:\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  FlexibleMultiTaskModel(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_log_sigmas): ParameterDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (density): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (Cp): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (Rg): Parameter containing: [torch.FloatTensor of size ]\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (encoder): FoundationEncoder(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (shared): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=190, out_features=256, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layer): Linear(in_features=256, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (normal): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (deposit): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (0): Linear(in_features=128, out_features=128, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (1): Tanh()\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (task_heads): ModuleDict(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (density): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (Cp): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      (Rg): RegressionHead(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        (net): LinearBlock(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          (layers): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (0): Sequential(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (0): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (layer): Linear(in_features=128, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (normal): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m                (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            (1): LinearLayer(\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (layer): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m              (activation): LeakyReLU(negative_slope=0.1)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m            )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m          )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m        )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m      )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m    (disabled_task_heads): ModuleDict()\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m178\u001b[0m - \u001b[1m  )\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mFlexibleMultiTaskModel initialization complete.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1384\u001b[0m - \u001b[1mLoaded shared_encoder optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded density task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded Cp task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1398\u001b[0m - \u001b[1mLoaded Rg task optimizer state from checkpoint\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36m_load_checkpoint_from_dict\u001b[0m:\u001b[36m1406\u001b[0m - \u001b[1mSuccessfully loaded 4 optimizer states from dict format\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m403\u001b[0m - \u001b[1mAdded task 'linear_expansion' (type=REGRESSION, enabled=True).\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36madd_task\u001b[0m:\u001b[36m407\u001b[0m - \u001b[1mActivated tasks during add_task: linear_expansion\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[32m2025-10-31 08:41:29.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: TrainerFn.FITTING ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (71725) into train_val (64552) and test (7173) using seed 24.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (64552) into train (57379) and val (7173) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=57379, Validation=7173, Test=7173\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m462\u001b[0m - \u001b[1m--- Creating 'fit' stage datasets (train/val) ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m464\u001b[0m - \u001b[1mCreating train_dataset with 57379 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[train_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[train_dataset] Final x_formula shape: torch.Size([57379, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to ../artifacts/polymers_incremental_tasks/Stage3_Rg/prediction/predictions.parquet\n",
      "Saved metrics to ../artifacts/polymers_incremental_tasks/Stage3_Rg/prediction/metrics.json\n",
      "=== Stage 4 (linear_expansion) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 08:41:29.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'Cp' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:29.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[train_dataset] Processing enabled task 'linear_expansion' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:30.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[train_dataset] CompoundDataset initialization complete. Processed 4 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:30.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36m_build_fit_datasets\u001b[0m:\u001b[36m483\u001b[0m - \u001b[1mCreating val_dataset with 7173 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:30.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[val_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:30.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[val_dataset] Final x_formula shape: torch.Size([7173, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:30.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:30.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'Cp' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:30.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:30.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[val_dataset] Processing enabled task 'linear_expansion' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:30.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[val_dataset] CompoundDataset initialization complete. Processed 4 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:30.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'TrainerFn.FITTING' complete ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:41:30.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexible_multi_task_model\u001b[0m:\u001b[36mconfigure_optimizers\u001b[0m:\u001b[36m1037\u001b[0m - \u001b[1mAdded 4 task_log_sigmas parameters to the main optimizer.\u001b[0m\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:317: The lr scheduler dict contains the key(s) ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n",
      "\n",
      "  | Name                | Type              | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | task_log_sigmas     | ParameterDict     | 4      | train\n",
      "1 | encoder             | FoundationEncoder | 99.1 K | train\n",
      "2 | shared              | LinearBlock       | 82.6 K | train\n",
      "3 | deposit             | Sequential        | 16.5 K | train\n",
      "4 | task_heads          | ModuleDict        | 33.8 K | train\n",
      "5 | disabled_task_heads | ModuleDict        | 0      | train\n",
      "------------------------------------------------------------------\n",
      "132 K     Trainable params\n",
      "0         Non-trainable params\n",
      "132 K     Total params\n",
      "0.531     Total estimated model params size (MB)\n",
      "56        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 32.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuchang/projects/foundation_model/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 225/225 [00:04<00:00, 49.17it/s, v_num=0, train_final_loss_step=1112.0, val_final_loss=995.0, train_final_loss_epoch=1.01e+3]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 225/225 [00:04<00:00, 48.79it/s, v_num=0, train_final_loss_step=1112.0, val_final_loss=995.0, train_final_loss_epoch=1.01e+3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 08:43:03.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1m--- Setting up DataModule for stage: test ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:43:03.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m561\u001b[0m - \u001b[1mTotal samples available before splitting (from attributes_df index): 71725\u001b[0m\n",
      "\u001b[32m2025-10-31 08:43:03.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mData split strategy: Performing random train/val/test splits based on full_idx (derived from attributes_df).\u001b[0m\n",
      "\u001b[32m2025-10-31 08:43:03.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m594\u001b[0m - \u001b[1mTest split ratio: 0.1, Validation split ratio (of non-test): 0.1\u001b[0m\n",
      "\u001b[32m2025-10-31 08:43:03.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m606\u001b[0m - \u001b[1mSplit full data (71725) into train_val (64552) and test (7173) using seed 24.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best checkpoint: /Users/liuchang/projects/foundation_model/artifacts/polymers_incremental_tasks/Stage4_linear_expansion/checkpoints/linear_expansion-epoch=19-val_final_loss=994.6105.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-31 08:43:03.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m632\u001b[0m - \u001b[1mSplit train_val (64552) into train (57379) and val (7173) using seed 42, effective_val_split 0.111.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:43:03.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m658\u001b[0m - \u001b[1mFinal dataset sizes after splitting: Train=57379, Validation=7173, Test=7173\u001b[0m\n",
      "\u001b[32m2025-10-31 08:43:03.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m666\u001b[0m - \u001b[1m--- Creating 'test' stage dataset ---\u001b[0m\n",
      "\u001b[32m2025-10-31 08:43:03.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m668\u001b[0m - \u001b[1mCreating test_dataset with 7173 samples.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:43:03.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1m[test_dataset] Initializing CompoundDataset...\u001b[0m\n",
      "\u001b[32m2025-10-31 08:43:03.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1m[test_dataset] Final x_formula shape: torch.Size([7173, 190])\u001b[0m\n",
      "\u001b[32m2025-10-31 08:43:03.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'density' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:43:03.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'Cp' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:43:03.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'Rg' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:43:03.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m[test_dataset] Processing enabled task 'linear_expansion' (type: REGRESSION)\u001b[0m\n",
      "\u001b[32m2025-10-31 08:43:03.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1m[test_dataset] CompoundDataset initialization complete. Processed 4 enabled tasks.\u001b[0m\n",
      "\u001b[32m2025-10-31 08:43:03.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatamodule\u001b[0m:\u001b[36msetup\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1m--- DataModule setup for stage 'test' complete ---\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to ../artifacts/polymers_incremental_tasks/Stage4_linear_expansion/prediction/predictions.parquet\n",
      "Saved metrics to ../artifacts/polymers_incremental_tasks/Stage4_linear_expansion/prediction/metrics.json\n"
     ]
    }
   ],
   "source": [
    "stage_records: list[dict] = []\n",
    "previous_checkpoint: str | None = None\n",
    "\n",
    "for stage_idx, task_name in enumerate(TASK_SEQUENCE, start=1):\n",
    "    stage_task_names = TASK_SEQUENCE[:stage_idx]\n",
    "    stage_label = f'Stage {stage_idx}'\n",
    "    print(f\"=== {stage_label} ({task_name}) ===\")\n",
    "\n",
    "    task_configs = make_task_configs(stage_task_names)\n",
    "    datamodule = build_datamodule(task_configs)\n",
    "\n",
    "    if previous_checkpoint is None:\n",
    "        model = FlexibleMultiTaskModel(\n",
    "            shared_block_dims=SHARED_BLOCK_DIMS,\n",
    "            task_configs=task_configs,\n",
    "            enable_learnable_loss_balancer=True,\n",
    "            shared_block_optimizer=OptimizerConfig(lr=5e-2),\n",
    "        )\n",
    "    else:\n",
    "        model = FlexibleMultiTaskModel.load_from_checkpoint(\n",
    "            checkpoint_path=previous_checkpoint,\n",
    "            strict=False,\n",
    "            enable_learnable_loss_balancer=True,\n",
    "        )\n",
    "        existing_tasks = set(model.task_heads.keys())\n",
    "        new_task_configs = [cfg for cfg in task_configs if cfg.name not in existing_tasks]\n",
    "        if new_task_configs:\n",
    "            model.add_task(*new_task_configs)\n",
    "\n",
    "    stage_root = ARTIFACT_ROOT / f'Stage{stage_idx}_{task_name}'\n",
    "    stage_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    checkpoint_cb = ModelCheckpoint(\n",
    "        dirpath=stage_root / 'checkpoints',\n",
    "        filename=f\"{task_name}-{{epoch:02d}}-{{val_final_loss:.4f}}\",\n",
    "        monitor='val_final_loss',\n",
    "        mode='min',\n",
    "        save_top_k=1,\n",
    "    )\n",
    "    early_stopping = EarlyStopping(monitor='val_final_loss', mode='min', patience=10)\n",
    "    csv_logger = CSVLogger(save_dir=stage_root / 'logs', name='csv')\n",
    "    tensorboard_logger = TensorBoardLogger(save_dir=stage_root / 'logs', name='tensorboard')\n",
    "\n",
    "    trainer = Trainer(\n",
    "        max_epochs=MAX_EPOCHS,\n",
    "        accelerator='auto',\n",
    "        devices='auto',\n",
    "        callbacks=[checkpoint_cb, early_stopping],\n",
    "        logger=[csv_logger, tensorboard_logger],\n",
    "        log_every_n_steps=LOG_EVERY_N_STEPS,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule=datamodule)\n",
    "    best_model_path = checkpoint_cb.best_model_path\n",
    "    print(f'Best checkpoint: {best_model_path}')\n",
    "\n",
    "    if best_model_path:\n",
    "        state = torch.load(best_model_path, map_location='cpu', weights_only=True)\n",
    "        state_dict = state.get('state_dict', state)\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "    prediction_dir = stage_root / 'prediction'\n",
    "    plot_test_predictions(\n",
    "        model,\n",
    "        datamodule,\n",
    "        stage_num=stage_idx,\n",
    "        stage_tasks=stage_task_names,\n",
    "        new_task_name=task_name,\n",
    "        prediction_dir=prediction_dir,\n",
    "    )\n",
    "\n",
    "    stage_records.append({\n",
    "        'stage': stage_idx,\n",
    "        'label': stage_label,\n",
    "        'task_names': stage_task_names,\n",
    "        'new_task_name': task_name,\n",
    "        'checkpoint': best_model_path,\n",
    "        'prediction_dir': prediction_dir,\n",
    "        'datamodule': datamodule,\n",
    "        'model': model,\n",
    "    })\n",
    "\n",
    "    previous_checkpoint = best_model_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundation-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
